{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'sample_submission.csv', 'test.csv', 'train.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "d = \"C:\\kaggle_data\\credit_card\"\n",
    "lst = os.listdir(d)\n",
    "print(lst)\n",
    "train = pd.read_csv(d + '\\\\' +lst[3])\n",
    "test = pd.read_csv(d + '\\\\' +lst[2])\n",
    "ss = pd.read_csv(d + '\\\\' +lst[1])\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True) \n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-guatemala",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-attention",
   "metadata": {},
   "source": [
    "### family_type\n",
    "- 'Married', 'Civil marriage'\n",
    "- 'Separated',  'Widow'\n",
    "- 'Single / not married'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "internal-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Married, Civil marriage\n",
    "train['income_per_size'] = np.log(train['income_total']/train['family_size'])\n",
    "test['income_per_size'] = np.log(test['income_total']/test['family_size'])\n",
    "train.loc[(train['family_type']=='Married')|(train['family_type']=='Civil marriage'),'income_per_size']\\\n",
    "= train['income_per_size'] * 2\n",
    "\n",
    "test.loc[(test['family_type']=='Married')|(test['family_type']=='Civil marriage'),'income_per_size']\\\n",
    "= test['income_per_size'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "internal-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_marry(x):\n",
    "    if x == 'Married' or x =='Civil marriage':\n",
    "        return '0'\n",
    "    elif x == 'Separated' or x == 'Widow':\n",
    "        return '1'\n",
    "    else:\n",
    "        return '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accomplished-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안 덮어쓰기\n",
    "for df in [train,test]:\n",
    "    df['family_bins'] = df['family_type'].apply(simple_marry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_total을 로그변환 한 새로운 feature log_income\n",
    "# 기존 칼럼 삭제\n",
    "train['log_income'] = np.log(train['income_total'])\n",
    "train = train.drop('income_total',1)\n",
    "test['log_income'] = np.log(test['income_total'])\n",
    "test = test.drop('income_total',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constant-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car와 reality를 합친 새로운 칼럼 careality\n",
    "train['car'] =train['car'].apply(lambda x: int(x=='Y'))\n",
    "train['reality'] =train['reality'].apply(lambda x: int(x=='Y'))\n",
    "test['car'] =test['car'].apply(lambda x: int(x=='Y'))\n",
    "test['reality'] =test['reality'].apply(lambda x: int(x=='Y'))\n",
    "\n",
    "train['careality'] = train['car'] + train['reality']\n",
    "train = train.drop(['car', 'reality'],1)\n",
    "\n",
    "test['careality'] = test['car'] + test['reality']\n",
    "test = test.drop(['car', 'reality'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latest-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "maritime-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-people",
   "metadata": {},
   "source": [
    "### \n",
    "- income_total\n",
    "- begin_month\n",
    "- DAYS_BIRTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forbidden-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 'income_total'\n",
    "# k = 2.2\n",
    "# mean = train[c].mean()\n",
    "# std = train[c].std()\n",
    "# idxs = train.loc[(train[c]>= mean + k*std)|\\\n",
    "#                 (train[c]<= mean - k*std)].index\n",
    "# train = train.drop(idxs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exposed-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out: 아웃라이어\n",
    "out_train = train.loc[train.DAYS_EMPLOYED>0]\n",
    "in_train = train.loc[train.DAYS_EMPLOYED<=0]\n",
    "\n",
    "\n",
    "out_test = test.loc[test.DAYS_EMPLOYED>0]\n",
    "in_test = test.loc[test.DAYS_EMPLOYED<=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-geometry",
   "metadata": {},
   "source": [
    "<!-- ###\n",
    "- DAYS_EMPLOYED -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-fabric",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "precise-dating",
   "metadata": {},
   "source": [
    "# 모델링, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "primary-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train = out_train.reset_index()\n",
    "in_train = in_train.reset_index()\n",
    "\n",
    "out_test = out_test.reset_index()\n",
    "in_test = in_test.reset_index()\n",
    "\n",
    "idx_out_train = out_train.pop('index')\n",
    "idx_out_test = out_test.pop('index')\n",
    "\n",
    "idx_in_train = in_train.pop('index')\n",
    "idx_in_test = in_test.pop('index')\n",
    "\n",
    "out_train.drop('DAYS_EMPLOYED',inplace=True,axis=1)\n",
    "out_test.drop('DAYS_EMPLOYED',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dimensional-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spoken-sending",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tr(train):\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=42)\n",
    "    folds=[]\n",
    "    losses=[]\n",
    "    for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "        folds.append((train_idx, valid_idx))\n",
    "    random.seed(42)\n",
    "    lgb_models={}\n",
    "    for fold in range(n):\n",
    "        train_idx, valid_idx = folds[fold]\n",
    "        X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                             train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "        lgb = LGBMClassifier(n_estimators=1000)\n",
    "        lgb.fit(X_train, y_train, \n",
    "                eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "                early_stopping_rounds=30)\n",
    "        lgb_models[fold]=lgb\n",
    "        losses.append(log_loss(y_valid, lgb.predict_proba(X_valid)))\n",
    "    ls = sum(losses)/n\n",
    "    print('평균{ls}')\n",
    "    return ls, lgb_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "serious-percentage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 0.856892\tvalid_1's multi_logloss: 0.859591\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.832345\tvalid_1's multi_logloss: 0.838393\n",
      "[3]\ttraining's multi_logloss: 0.812914\tvalid_1's multi_logloss: 0.826085\n",
      "[4]\ttraining's multi_logloss: 0.796487\tvalid_1's multi_logloss: 0.814487\n",
      "[5]\ttraining's multi_logloss: 0.782601\tvalid_1's multi_logloss: 0.806546\n",
      "[6]\ttraining's multi_logloss: 0.769915\tvalid_1's multi_logloss: 0.799696\n",
      "[7]\ttraining's multi_logloss: 0.758574\tvalid_1's multi_logloss: 0.793876\n",
      "[8]\ttraining's multi_logloss: 0.748874\tvalid_1's multi_logloss: 0.790049\n",
      "[9]\ttraining's multi_logloss: 0.738978\tvalid_1's multi_logloss: 0.783482\n",
      "[10]\ttraining's multi_logloss: 0.728735\tvalid_1's multi_logloss: 0.776063\n",
      "[11]\ttraining's multi_logloss: 0.719633\tvalid_1's multi_logloss: 0.771396\n",
      "[12]\ttraining's multi_logloss: 0.710839\tvalid_1's multi_logloss: 0.76608\n",
      "[13]\ttraining's multi_logloss: 0.704135\tvalid_1's multi_logloss: 0.76242\n",
      "[14]\ttraining's multi_logloss: 0.697514\tvalid_1's multi_logloss: 0.759586\n",
      "[15]\ttraining's multi_logloss: 0.690823\tvalid_1's multi_logloss: 0.755423\n",
      "[16]\ttraining's multi_logloss: 0.684238\tvalid_1's multi_logloss: 0.751369\n",
      "[17]\ttraining's multi_logloss: 0.677866\tvalid_1's multi_logloss: 0.749484\n",
      "[18]\ttraining's multi_logloss: 0.671607\tvalid_1's multi_logloss: 0.746079\n",
      "[19]\ttraining's multi_logloss: 0.666439\tvalid_1's multi_logloss: 0.745345\n",
      "[20]\ttraining's multi_logloss: 0.661028\tvalid_1's multi_logloss: 0.744345\n",
      "[21]\ttraining's multi_logloss: 0.655731\tvalid_1's multi_logloss: 0.742091\n",
      "[22]\ttraining's multi_logloss: 0.650574\tvalid_1's multi_logloss: 0.739854\n",
      "[23]\ttraining's multi_logloss: 0.645252\tvalid_1's multi_logloss: 0.738021\n",
      "[24]\ttraining's multi_logloss: 0.640134\tvalid_1's multi_logloss: 0.737933\n",
      "[25]\ttraining's multi_logloss: 0.635241\tvalid_1's multi_logloss: 0.736048\n",
      "[26]\ttraining's multi_logloss: 0.630465\tvalid_1's multi_logloss: 0.7344\n",
      "[27]\ttraining's multi_logloss: 0.62605\tvalid_1's multi_logloss: 0.732886\n",
      "[28]\ttraining's multi_logloss: 0.621907\tvalid_1's multi_logloss: 0.731998\n",
      "[29]\ttraining's multi_logloss: 0.617413\tvalid_1's multi_logloss: 0.731091\n",
      "[30]\ttraining's multi_logloss: 0.61261\tvalid_1's multi_logloss: 0.729528\n",
      "[31]\ttraining's multi_logloss: 0.608693\tvalid_1's multi_logloss: 0.729572\n",
      "[32]\ttraining's multi_logloss: 0.604975\tvalid_1's multi_logloss: 0.728325\n",
      "[33]\ttraining's multi_logloss: 0.601566\tvalid_1's multi_logloss: 0.727197\n",
      "[34]\ttraining's multi_logloss: 0.598245\tvalid_1's multi_logloss: 0.727169\n",
      "[35]\ttraining's multi_logloss: 0.594823\tvalid_1's multi_logloss: 0.726973\n",
      "[36]\ttraining's multi_logloss: 0.591363\tvalid_1's multi_logloss: 0.725132\n",
      "[37]\ttraining's multi_logloss: 0.587806\tvalid_1's multi_logloss: 0.724943\n",
      "[38]\ttraining's multi_logloss: 0.584439\tvalid_1's multi_logloss: 0.725917\n",
      "[39]\ttraining's multi_logloss: 0.580675\tvalid_1's multi_logloss: 0.725805\n",
      "[40]\ttraining's multi_logloss: 0.577101\tvalid_1's multi_logloss: 0.724183\n",
      "[41]\ttraining's multi_logloss: 0.573422\tvalid_1's multi_logloss: 0.723064\n",
      "[42]\ttraining's multi_logloss: 0.569993\tvalid_1's multi_logloss: 0.721964\n",
      "[43]\ttraining's multi_logloss: 0.566919\tvalid_1's multi_logloss: 0.722808\n",
      "[44]\ttraining's multi_logloss: 0.563033\tvalid_1's multi_logloss: 0.721754\n",
      "[45]\ttraining's multi_logloss: 0.560374\tvalid_1's multi_logloss: 0.721703\n",
      "[46]\ttraining's multi_logloss: 0.556661\tvalid_1's multi_logloss: 0.720881\n",
      "[47]\ttraining's multi_logloss: 0.553596\tvalid_1's multi_logloss: 0.721187\n",
      "[48]\ttraining's multi_logloss: 0.55043\tvalid_1's multi_logloss: 0.720307\n",
      "[49]\ttraining's multi_logloss: 0.547797\tvalid_1's multi_logloss: 0.720533\n",
      "[50]\ttraining's multi_logloss: 0.545189\tvalid_1's multi_logloss: 0.720918\n",
      "[51]\ttraining's multi_logloss: 0.542383\tvalid_1's multi_logloss: 0.720163\n",
      "[52]\ttraining's multi_logloss: 0.539565\tvalid_1's multi_logloss: 0.718759\n",
      "[53]\ttraining's multi_logloss: 0.536795\tvalid_1's multi_logloss: 0.716755\n",
      "[54]\ttraining's multi_logloss: 0.533379\tvalid_1's multi_logloss: 0.716218\n",
      "[55]\ttraining's multi_logloss: 0.530708\tvalid_1's multi_logloss: 0.714996\n",
      "[56]\ttraining's multi_logloss: 0.52767\tvalid_1's multi_logloss: 0.715266\n",
      "[57]\ttraining's multi_logloss: 0.524799\tvalid_1's multi_logloss: 0.71598\n",
      "[58]\ttraining's multi_logloss: 0.521892\tvalid_1's multi_logloss: 0.714832\n",
      "[59]\ttraining's multi_logloss: 0.518875\tvalid_1's multi_logloss: 0.715151\n",
      "[60]\ttraining's multi_logloss: 0.516136\tvalid_1's multi_logloss: 0.714738\n",
      "[61]\ttraining's multi_logloss: 0.513581\tvalid_1's multi_logloss: 0.71498\n",
      "[62]\ttraining's multi_logloss: 0.511237\tvalid_1's multi_logloss: 0.715296\n",
      "[63]\ttraining's multi_logloss: 0.508554\tvalid_1's multi_logloss: 0.715625\n",
      "[64]\ttraining's multi_logloss: 0.505857\tvalid_1's multi_logloss: 0.716092\n",
      "[65]\ttraining's multi_logloss: 0.503797\tvalid_1's multi_logloss: 0.715855\n",
      "[66]\ttraining's multi_logloss: 0.501051\tvalid_1's multi_logloss: 0.715809\n",
      "[67]\ttraining's multi_logloss: 0.498501\tvalid_1's multi_logloss: 0.714769\n",
      "[68]\ttraining's multi_logloss: 0.496386\tvalid_1's multi_logloss: 0.714393\n",
      "[69]\ttraining's multi_logloss: 0.493536\tvalid_1's multi_logloss: 0.714544\n",
      "[70]\ttraining's multi_logloss: 0.491242\tvalid_1's multi_logloss: 0.715811\n",
      "[71]\ttraining's multi_logloss: 0.488774\tvalid_1's multi_logloss: 0.716001\n",
      "[72]\ttraining's multi_logloss: 0.486786\tvalid_1's multi_logloss: 0.716683\n",
      "[73]\ttraining's multi_logloss: 0.48449\tvalid_1's multi_logloss: 0.716832\n",
      "[74]\ttraining's multi_logloss: 0.48234\tvalid_1's multi_logloss: 0.716736\n",
      "[75]\ttraining's multi_logloss: 0.480132\tvalid_1's multi_logloss: 0.716659\n",
      "[76]\ttraining's multi_logloss: 0.477923\tvalid_1's multi_logloss: 0.716801\n",
      "[77]\ttraining's multi_logloss: 0.475922\tvalid_1's multi_logloss: 0.716957\n",
      "[78]\ttraining's multi_logloss: 0.473597\tvalid_1's multi_logloss: 0.717182\n",
      "[79]\ttraining's multi_logloss: 0.471608\tvalid_1's multi_logloss: 0.71721\n",
      "[80]\ttraining's multi_logloss: 0.4692\tvalid_1's multi_logloss: 0.717581\n",
      "[81]\ttraining's multi_logloss: 0.466729\tvalid_1's multi_logloss: 0.717088\n",
      "[82]\ttraining's multi_logloss: 0.464268\tvalid_1's multi_logloss: 0.717884\n",
      "[83]\ttraining's multi_logloss: 0.462172\tvalid_1's multi_logloss: 0.717022\n",
      "[84]\ttraining's multi_logloss: 0.460294\tvalid_1's multi_logloss: 0.718159\n",
      "[85]\ttraining's multi_logloss: 0.458339\tvalid_1's multi_logloss: 0.718766\n",
      "[86]\ttraining's multi_logloss: 0.456479\tvalid_1's multi_logloss: 0.718179\n",
      "[87]\ttraining's multi_logloss: 0.454156\tvalid_1's multi_logloss: 0.717641\n",
      "[88]\ttraining's multi_logloss: 0.451689\tvalid_1's multi_logloss: 0.718477\n",
      "[89]\ttraining's multi_logloss: 0.449791\tvalid_1's multi_logloss: 0.718746\n",
      "[90]\ttraining's multi_logloss: 0.447589\tvalid_1's multi_logloss: 0.720258\n",
      "[91]\ttraining's multi_logloss: 0.445515\tvalid_1's multi_logloss: 0.720067\n",
      "[92]\ttraining's multi_logloss: 0.443874\tvalid_1's multi_logloss: 0.722134\n",
      "[93]\ttraining's multi_logloss: 0.441553\tvalid_1's multi_logloss: 0.723019\n",
      "[94]\ttraining's multi_logloss: 0.43942\tvalid_1's multi_logloss: 0.723456\n",
      "[95]\ttraining's multi_logloss: 0.437536\tvalid_1's multi_logloss: 0.724124\n",
      "[96]\ttraining's multi_logloss: 0.435601\tvalid_1's multi_logloss: 0.723768\n",
      "[97]\ttraining's multi_logloss: 0.433687\tvalid_1's multi_logloss: 0.724311\n",
      "[98]\ttraining's multi_logloss: 0.431228\tvalid_1's multi_logloss: 0.724394\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's multi_logloss: 0.496386\tvalid_1's multi_logloss: 0.714393\n",
      "[1]\ttraining's multi_logloss: 0.85689\tvalid_1's multi_logloss: 0.866714\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.832792\tvalid_1's multi_logloss: 0.852374\n",
      "[3]\ttraining's multi_logloss: 0.81282\tvalid_1's multi_logloss: 0.838252\n",
      "[4]\ttraining's multi_logloss: 0.796467\tvalid_1's multi_logloss: 0.828836\n",
      "[5]\ttraining's multi_logloss: 0.781661\tvalid_1's multi_logloss: 0.821054\n",
      "[6]\ttraining's multi_logloss: 0.768439\tvalid_1's multi_logloss: 0.81424\n",
      "[7]\ttraining's multi_logloss: 0.756638\tvalid_1's multi_logloss: 0.809323\n",
      "[8]\ttraining's multi_logloss: 0.745725\tvalid_1's multi_logloss: 0.804492\n",
      "[9]\ttraining's multi_logloss: 0.736497\tvalid_1's multi_logloss: 0.800361\n",
      "[10]\ttraining's multi_logloss: 0.726985\tvalid_1's multi_logloss: 0.797874\n",
      "[11]\ttraining's multi_logloss: 0.718989\tvalid_1's multi_logloss: 0.796619\n",
      "[12]\ttraining's multi_logloss: 0.710128\tvalid_1's multi_logloss: 0.791006\n",
      "[13]\ttraining's multi_logloss: 0.702109\tvalid_1's multi_logloss: 0.787203\n",
      "[14]\ttraining's multi_logloss: 0.695557\tvalid_1's multi_logloss: 0.784657\n",
      "[15]\ttraining's multi_logloss: 0.689282\tvalid_1's multi_logloss: 0.78205\n",
      "[16]\ttraining's multi_logloss: 0.68297\tvalid_1's multi_logloss: 0.777994\n",
      "[17]\ttraining's multi_logloss: 0.676758\tvalid_1's multi_logloss: 0.776513\n",
      "[18]\ttraining's multi_logloss: 0.671422\tvalid_1's multi_logloss: 0.774477\n",
      "[19]\ttraining's multi_logloss: 0.665971\tvalid_1's multi_logloss: 0.773377\n",
      "[20]\ttraining's multi_logloss: 0.660907\tvalid_1's multi_logloss: 0.773366\n",
      "[21]\ttraining's multi_logloss: 0.654734\tvalid_1's multi_logloss: 0.772485\n",
      "[22]\ttraining's multi_logloss: 0.649458\tvalid_1's multi_logloss: 0.77112\n",
      "[23]\ttraining's multi_logloss: 0.644944\tvalid_1's multi_logloss: 0.769739\n",
      "[24]\ttraining's multi_logloss: 0.639905\tvalid_1's multi_logloss: 0.768495\n",
      "[25]\ttraining's multi_logloss: 0.635048\tvalid_1's multi_logloss: 0.767429\n",
      "[26]\ttraining's multi_logloss: 0.630661\tvalid_1's multi_logloss: 0.765749\n",
      "[27]\ttraining's multi_logloss: 0.625276\tvalid_1's multi_logloss: 0.765642\n",
      "[28]\ttraining's multi_logloss: 0.620434\tvalid_1's multi_logloss: 0.765337\n",
      "[29]\ttraining's multi_logloss: 0.616627\tvalid_1's multi_logloss: 0.76468\n",
      "[30]\ttraining's multi_logloss: 0.612381\tvalid_1's multi_logloss: 0.762439\n",
      "[31]\ttraining's multi_logloss: 0.608014\tvalid_1's multi_logloss: 0.761824\n",
      "[32]\ttraining's multi_logloss: 0.603688\tvalid_1's multi_logloss: 0.761266\n",
      "[33]\ttraining's multi_logloss: 0.600261\tvalid_1's multi_logloss: 0.761484\n",
      "[34]\ttraining's multi_logloss: 0.596521\tvalid_1's multi_logloss: 0.761308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\ttraining's multi_logloss: 0.592755\tvalid_1's multi_logloss: 0.76072\n",
      "[36]\ttraining's multi_logloss: 0.589724\tvalid_1's multi_logloss: 0.760664\n",
      "[37]\ttraining's multi_logloss: 0.586094\tvalid_1's multi_logloss: 0.760071\n",
      "[38]\ttraining's multi_logloss: 0.582691\tvalid_1's multi_logloss: 0.759397\n",
      "[39]\ttraining's multi_logloss: 0.57979\tvalid_1's multi_logloss: 0.760172\n",
      "[40]\ttraining's multi_logloss: 0.576253\tvalid_1's multi_logloss: 0.759815\n",
      "[41]\ttraining's multi_logloss: 0.572711\tvalid_1's multi_logloss: 0.759635\n",
      "[42]\ttraining's multi_logloss: 0.569595\tvalid_1's multi_logloss: 0.759945\n",
      "[43]\ttraining's multi_logloss: 0.566677\tvalid_1's multi_logloss: 0.759337\n",
      "[44]\ttraining's multi_logloss: 0.563428\tvalid_1's multi_logloss: 0.760051\n",
      "[45]\ttraining's multi_logloss: 0.560441\tvalid_1's multi_logloss: 0.760567\n",
      "[46]\ttraining's multi_logloss: 0.556924\tvalid_1's multi_logloss: 0.761277\n",
      "[47]\ttraining's multi_logloss: 0.554396\tvalid_1's multi_logloss: 0.761072\n",
      "[48]\ttraining's multi_logloss: 0.551899\tvalid_1's multi_logloss: 0.760717\n",
      "[49]\ttraining's multi_logloss: 0.549281\tvalid_1's multi_logloss: 0.760472\n",
      "[50]\ttraining's multi_logloss: 0.546032\tvalid_1's multi_logloss: 0.758547\n",
      "[51]\ttraining's multi_logloss: 0.543603\tvalid_1's multi_logloss: 0.758289\n",
      "[52]\ttraining's multi_logloss: 0.540134\tvalid_1's multi_logloss: 0.758532\n",
      "[53]\ttraining's multi_logloss: 0.53745\tvalid_1's multi_logloss: 0.758704\n",
      "[54]\ttraining's multi_logloss: 0.534566\tvalid_1's multi_logloss: 0.757911\n",
      "[55]\ttraining's multi_logloss: 0.531839\tvalid_1's multi_logloss: 0.757679\n",
      "[56]\ttraining's multi_logloss: 0.529144\tvalid_1's multi_logloss: 0.758185\n",
      "[57]\ttraining's multi_logloss: 0.526087\tvalid_1's multi_logloss: 0.758278\n",
      "[58]\ttraining's multi_logloss: 0.522907\tvalid_1's multi_logloss: 0.757976\n",
      "[59]\ttraining's multi_logloss: 0.520046\tvalid_1's multi_logloss: 0.757388\n",
      "[60]\ttraining's multi_logloss: 0.517143\tvalid_1's multi_logloss: 0.757053\n",
      "[61]\ttraining's multi_logloss: 0.514735\tvalid_1's multi_logloss: 0.756506\n",
      "[62]\ttraining's multi_logloss: 0.512257\tvalid_1's multi_logloss: 0.756579\n",
      "[63]\ttraining's multi_logloss: 0.509656\tvalid_1's multi_logloss: 0.755784\n",
      "[64]\ttraining's multi_logloss: 0.507164\tvalid_1's multi_logloss: 0.755627\n",
      "[65]\ttraining's multi_logloss: 0.5048\tvalid_1's multi_logloss: 0.753658\n",
      "[66]\ttraining's multi_logloss: 0.502187\tvalid_1's multi_logloss: 0.754523\n",
      "[67]\ttraining's multi_logloss: 0.499676\tvalid_1's multi_logloss: 0.755279\n",
      "[68]\ttraining's multi_logloss: 0.497284\tvalid_1's multi_logloss: 0.755215\n",
      "[69]\ttraining's multi_logloss: 0.494236\tvalid_1's multi_logloss: 0.755624\n",
      "[70]\ttraining's multi_logloss: 0.491407\tvalid_1's multi_logloss: 0.755266\n",
      "[71]\ttraining's multi_logloss: 0.488842\tvalid_1's multi_logloss: 0.754625\n",
      "[72]\ttraining's multi_logloss: 0.486203\tvalid_1's multi_logloss: 0.755006\n",
      "[73]\ttraining's multi_logloss: 0.483387\tvalid_1's multi_logloss: 0.755216\n",
      "[74]\ttraining's multi_logloss: 0.480944\tvalid_1's multi_logloss: 0.755666\n",
      "[75]\ttraining's multi_logloss: 0.478922\tvalid_1's multi_logloss: 0.755319\n",
      "[76]\ttraining's multi_logloss: 0.476501\tvalid_1's multi_logloss: 0.756409\n",
      "[77]\ttraining's multi_logloss: 0.474116\tvalid_1's multi_logloss: 0.757171\n",
      "[78]\ttraining's multi_logloss: 0.471464\tvalid_1's multi_logloss: 0.756833\n",
      "[79]\ttraining's multi_logloss: 0.469397\tvalid_1's multi_logloss: 0.75727\n",
      "[80]\ttraining's multi_logloss: 0.46695\tvalid_1's multi_logloss: 0.757707\n",
      "[81]\ttraining's multi_logloss: 0.464753\tvalid_1's multi_logloss: 0.758408\n",
      "[82]\ttraining's multi_logloss: 0.462851\tvalid_1's multi_logloss: 0.758582\n",
      "[83]\ttraining's multi_logloss: 0.460992\tvalid_1's multi_logloss: 0.757964\n",
      "[84]\ttraining's multi_logloss: 0.458472\tvalid_1's multi_logloss: 0.757573\n",
      "[85]\ttraining's multi_logloss: 0.456499\tvalid_1's multi_logloss: 0.757107\n",
      "[86]\ttraining's multi_logloss: 0.454223\tvalid_1's multi_logloss: 0.757281\n",
      "[87]\ttraining's multi_logloss: 0.45204\tvalid_1's multi_logloss: 0.757056\n",
      "[88]\ttraining's multi_logloss: 0.45001\tvalid_1's multi_logloss: 0.75676\n",
      "[89]\ttraining's multi_logloss: 0.448171\tvalid_1's multi_logloss: 0.755765\n",
      "[90]\ttraining's multi_logloss: 0.44627\tvalid_1's multi_logloss: 0.754231\n",
      "[91]\ttraining's multi_logloss: 0.444196\tvalid_1's multi_logloss: 0.755613\n",
      "[92]\ttraining's multi_logloss: 0.441965\tvalid_1's multi_logloss: 0.75659\n",
      "[93]\ttraining's multi_logloss: 0.439989\tvalid_1's multi_logloss: 0.756911\n",
      "[94]\ttraining's multi_logloss: 0.43818\tvalid_1's multi_logloss: 0.757305\n",
      "[95]\ttraining's multi_logloss: 0.436451\tvalid_1's multi_logloss: 0.757237\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's multi_logloss: 0.5048\tvalid_1's multi_logloss: 0.753658\n",
      "[1]\ttraining's multi_logloss: 0.858059\tvalid_1's multi_logloss: 0.867951\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.83441\tvalid_1's multi_logloss: 0.852885\n",
      "[3]\ttraining's multi_logloss: 0.815531\tvalid_1's multi_logloss: 0.838762\n",
      "[4]\ttraining's multi_logloss: 0.798402\tvalid_1's multi_logloss: 0.826962\n",
      "[5]\ttraining's multi_logloss: 0.783471\tvalid_1's multi_logloss: 0.820225\n",
      "[6]\ttraining's multi_logloss: 0.770744\tvalid_1's multi_logloss: 0.814103\n",
      "[7]\ttraining's multi_logloss: 0.759639\tvalid_1's multi_logloss: 0.807772\n",
      "[8]\ttraining's multi_logloss: 0.749184\tvalid_1's multi_logloss: 0.80125\n",
      "[9]\ttraining's multi_logloss: 0.738548\tvalid_1's multi_logloss: 0.794215\n",
      "[10]\ttraining's multi_logloss: 0.728963\tvalid_1's multi_logloss: 0.789372\n",
      "[11]\ttraining's multi_logloss: 0.721319\tvalid_1's multi_logloss: 0.785202\n",
      "[12]\ttraining's multi_logloss: 0.713242\tvalid_1's multi_logloss: 0.778958\n",
      "[13]\ttraining's multi_logloss: 0.706444\tvalid_1's multi_logloss: 0.777111\n",
      "[14]\ttraining's multi_logloss: 0.699442\tvalid_1's multi_logloss: 0.773667\n",
      "[15]\ttraining's multi_logloss: 0.692292\tvalid_1's multi_logloss: 0.772792\n",
      "[16]\ttraining's multi_logloss: 0.685815\tvalid_1's multi_logloss: 0.771558\n",
      "[17]\ttraining's multi_logloss: 0.679728\tvalid_1's multi_logloss: 0.768752\n",
      "[18]\ttraining's multi_logloss: 0.673269\tvalid_1's multi_logloss: 0.766755\n",
      "[19]\ttraining's multi_logloss: 0.667753\tvalid_1's multi_logloss: 0.764112\n",
      "[20]\ttraining's multi_logloss: 0.66259\tvalid_1's multi_logloss: 0.7633\n",
      "[21]\ttraining's multi_logloss: 0.657787\tvalid_1's multi_logloss: 0.761913\n",
      "[22]\ttraining's multi_logloss: 0.652714\tvalid_1's multi_logloss: 0.759153\n",
      "[23]\ttraining's multi_logloss: 0.647241\tvalid_1's multi_logloss: 0.758475\n",
      "[24]\ttraining's multi_logloss: 0.642204\tvalid_1's multi_logloss: 0.756943\n",
      "[25]\ttraining's multi_logloss: 0.637164\tvalid_1's multi_logloss: 0.756186\n",
      "[26]\ttraining's multi_logloss: 0.632857\tvalid_1's multi_logloss: 0.754296\n",
      "[27]\ttraining's multi_logloss: 0.628093\tvalid_1's multi_logloss: 0.75097\n",
      "[28]\ttraining's multi_logloss: 0.62298\tvalid_1's multi_logloss: 0.750118\n",
      "[29]\ttraining's multi_logloss: 0.618636\tvalid_1's multi_logloss: 0.747455\n",
      "[30]\ttraining's multi_logloss: 0.614385\tvalid_1's multi_logloss: 0.745799\n",
      "[31]\ttraining's multi_logloss: 0.609999\tvalid_1's multi_logloss: 0.745835\n",
      "[32]\ttraining's multi_logloss: 0.605643\tvalid_1's multi_logloss: 0.743575\n",
      "[33]\ttraining's multi_logloss: 0.601799\tvalid_1's multi_logloss: 0.743184\n",
      "[34]\ttraining's multi_logloss: 0.597826\tvalid_1's multi_logloss: 0.743234\n",
      "[35]\ttraining's multi_logloss: 0.593848\tvalid_1's multi_logloss: 0.740949\n",
      "[36]\ttraining's multi_logloss: 0.590432\tvalid_1's multi_logloss: 0.740492\n",
      "[37]\ttraining's multi_logloss: 0.586685\tvalid_1's multi_logloss: 0.739238\n",
      "[38]\ttraining's multi_logloss: 0.582655\tvalid_1's multi_logloss: 0.739029\n",
      "[39]\ttraining's multi_logloss: 0.578523\tvalid_1's multi_logloss: 0.737253\n",
      "[40]\ttraining's multi_logloss: 0.574567\tvalid_1's multi_logloss: 0.736504\n",
      "[41]\ttraining's multi_logloss: 0.571097\tvalid_1's multi_logloss: 0.736048\n",
      "[42]\ttraining's multi_logloss: 0.567654\tvalid_1's multi_logloss: 0.735412\n",
      "[43]\ttraining's multi_logloss: 0.564997\tvalid_1's multi_logloss: 0.734718\n",
      "[44]\ttraining's multi_logloss: 0.56147\tvalid_1's multi_logloss: 0.734779\n",
      "[45]\ttraining's multi_logloss: 0.558577\tvalid_1's multi_logloss: 0.733745\n",
      "[46]\ttraining's multi_logloss: 0.554972\tvalid_1's multi_logloss: 0.734463\n",
      "[47]\ttraining's multi_logloss: 0.552181\tvalid_1's multi_logloss: 0.733492\n",
      "[48]\ttraining's multi_logloss: 0.549339\tvalid_1's multi_logloss: 0.733363\n",
      "[49]\ttraining's multi_logloss: 0.546289\tvalid_1's multi_logloss: 0.733801\n",
      "[50]\ttraining's multi_logloss: 0.543669\tvalid_1's multi_logloss: 0.732829\n",
      "[51]\ttraining's multi_logloss: 0.539938\tvalid_1's multi_logloss: 0.732395\n",
      "[52]\ttraining's multi_logloss: 0.537062\tvalid_1's multi_logloss: 0.731029\n",
      "[53]\ttraining's multi_logloss: 0.534058\tvalid_1's multi_logloss: 0.730436\n",
      "[54]\ttraining's multi_logloss: 0.530852\tvalid_1's multi_logloss: 0.730428\n",
      "[55]\ttraining's multi_logloss: 0.527779\tvalid_1's multi_logloss: 0.730045\n",
      "[56]\ttraining's multi_logloss: 0.525156\tvalid_1's multi_logloss: 0.729837\n",
      "[57]\ttraining's multi_logloss: 0.522589\tvalid_1's multi_logloss: 0.729558\n",
      "[58]\ttraining's multi_logloss: 0.519933\tvalid_1's multi_logloss: 0.729464\n",
      "[59]\ttraining's multi_logloss: 0.517701\tvalid_1's multi_logloss: 0.729445\n",
      "[60]\ttraining's multi_logloss: 0.51557\tvalid_1's multi_logloss: 0.729428\n",
      "[61]\ttraining's multi_logloss: 0.513058\tvalid_1's multi_logloss: 0.729322\n",
      "[62]\ttraining's multi_logloss: 0.510607\tvalid_1's multi_logloss: 0.729299\n",
      "[63]\ttraining's multi_logloss: 0.50744\tvalid_1's multi_logloss: 0.728623\n",
      "[64]\ttraining's multi_logloss: 0.504804\tvalid_1's multi_logloss: 0.728784\n",
      "[65]\ttraining's multi_logloss: 0.502443\tvalid_1's multi_logloss: 0.728762\n",
      "[66]\ttraining's multi_logloss: 0.49951\tvalid_1's multi_logloss: 0.729384\n",
      "[67]\ttraining's multi_logloss: 0.496932\tvalid_1's multi_logloss: 0.729222\n",
      "[68]\ttraining's multi_logloss: 0.49438\tvalid_1's multi_logloss: 0.729037\n",
      "[69]\ttraining's multi_logloss: 0.491903\tvalid_1's multi_logloss: 0.729434\n",
      "[70]\ttraining's multi_logloss: 0.489484\tvalid_1's multi_logloss: 0.729259\n",
      "[71]\ttraining's multi_logloss: 0.486901\tvalid_1's multi_logloss: 0.729225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72]\ttraining's multi_logloss: 0.484658\tvalid_1's multi_logloss: 0.729145\n",
      "[73]\ttraining's multi_logloss: 0.482593\tvalid_1's multi_logloss: 0.72739\n",
      "[74]\ttraining's multi_logloss: 0.480254\tvalid_1's multi_logloss: 0.727203\n",
      "[75]\ttraining's multi_logloss: 0.478174\tvalid_1's multi_logloss: 0.727684\n",
      "[76]\ttraining's multi_logloss: 0.475936\tvalid_1's multi_logloss: 0.727989\n",
      "[77]\ttraining's multi_logloss: 0.473585\tvalid_1's multi_logloss: 0.72703\n",
      "[78]\ttraining's multi_logloss: 0.471547\tvalid_1's multi_logloss: 0.726947\n",
      "[79]\ttraining's multi_logloss: 0.46931\tvalid_1's multi_logloss: 0.727082\n",
      "[80]\ttraining's multi_logloss: 0.46705\tvalid_1's multi_logloss: 0.726155\n",
      "[81]\ttraining's multi_logloss: 0.464494\tvalid_1's multi_logloss: 0.725621\n",
      "[82]\ttraining's multi_logloss: 0.462006\tvalid_1's multi_logloss: 0.725047\n",
      "[83]\ttraining's multi_logloss: 0.459828\tvalid_1's multi_logloss: 0.72678\n",
      "[84]\ttraining's multi_logloss: 0.457647\tvalid_1's multi_logloss: 0.727\n",
      "[85]\ttraining's multi_logloss: 0.45542\tvalid_1's multi_logloss: 0.726104\n",
      "[86]\ttraining's multi_logloss: 0.453756\tvalid_1's multi_logloss: 0.726353\n",
      "[87]\ttraining's multi_logloss: 0.451569\tvalid_1's multi_logloss: 0.727046\n",
      "[88]\ttraining's multi_logloss: 0.449679\tvalid_1's multi_logloss: 0.725859\n",
      "[89]\ttraining's multi_logloss: 0.4477\tvalid_1's multi_logloss: 0.725885\n",
      "[90]\ttraining's multi_logloss: 0.445739\tvalid_1's multi_logloss: 0.727019\n",
      "[91]\ttraining's multi_logloss: 0.443723\tvalid_1's multi_logloss: 0.72708\n",
      "[92]\ttraining's multi_logloss: 0.441774\tvalid_1's multi_logloss: 0.727084\n",
      "[93]\ttraining's multi_logloss: 0.439927\tvalid_1's multi_logloss: 0.727883\n",
      "[94]\ttraining's multi_logloss: 0.437693\tvalid_1's multi_logloss: 0.727939\n",
      "[95]\ttraining's multi_logloss: 0.435349\tvalid_1's multi_logloss: 0.727699\n",
      "[96]\ttraining's multi_logloss: 0.433488\tvalid_1's multi_logloss: 0.726427\n",
      "[97]\ttraining's multi_logloss: 0.431364\tvalid_1's multi_logloss: 0.726359\n",
      "[98]\ttraining's multi_logloss: 0.429273\tvalid_1's multi_logloss: 0.725598\n",
      "[99]\ttraining's multi_logloss: 0.427399\tvalid_1's multi_logloss: 0.724419\n",
      "[100]\ttraining's multi_logloss: 0.425627\tvalid_1's multi_logloss: 0.724887\n",
      "[101]\ttraining's multi_logloss: 0.423634\tvalid_1's multi_logloss: 0.725144\n",
      "[102]\ttraining's multi_logloss: 0.421508\tvalid_1's multi_logloss: 0.724324\n",
      "[103]\ttraining's multi_logloss: 0.419729\tvalid_1's multi_logloss: 0.72481\n",
      "[104]\ttraining's multi_logloss: 0.418037\tvalid_1's multi_logloss: 0.724725\n",
      "[105]\ttraining's multi_logloss: 0.415983\tvalid_1's multi_logloss: 0.724715\n",
      "[106]\ttraining's multi_logloss: 0.414326\tvalid_1's multi_logloss: 0.724617\n",
      "[107]\ttraining's multi_logloss: 0.412571\tvalid_1's multi_logloss: 0.724561\n",
      "[108]\ttraining's multi_logloss: 0.410979\tvalid_1's multi_logloss: 0.724676\n",
      "[109]\ttraining's multi_logloss: 0.409397\tvalid_1's multi_logloss: 0.725863\n",
      "[110]\ttraining's multi_logloss: 0.407833\tvalid_1's multi_logloss: 0.72645\n",
      "[111]\ttraining's multi_logloss: 0.406309\tvalid_1's multi_logloss: 0.726995\n",
      "[112]\ttraining's multi_logloss: 0.404459\tvalid_1's multi_logloss: 0.727559\n",
      "[113]\ttraining's multi_logloss: 0.402734\tvalid_1's multi_logloss: 0.728143\n",
      "[114]\ttraining's multi_logloss: 0.401348\tvalid_1's multi_logloss: 0.729374\n",
      "[115]\ttraining's multi_logloss: 0.399922\tvalid_1's multi_logloss: 0.729178\n",
      "[116]\ttraining's multi_logloss: 0.397963\tvalid_1's multi_logloss: 0.729183\n",
      "[117]\ttraining's multi_logloss: 0.396265\tvalid_1's multi_logloss: 0.728702\n",
      "[118]\ttraining's multi_logloss: 0.394301\tvalid_1's multi_logloss: 0.729006\n",
      "[119]\ttraining's multi_logloss: 0.392957\tvalid_1's multi_logloss: 0.728887\n",
      "[120]\ttraining's multi_logloss: 0.391088\tvalid_1's multi_logloss: 0.729457\n",
      "[121]\ttraining's multi_logloss: 0.389356\tvalid_1's multi_logloss: 0.729883\n",
      "[122]\ttraining's multi_logloss: 0.387809\tvalid_1's multi_logloss: 0.730261\n",
      "[123]\ttraining's multi_logloss: 0.38614\tvalid_1's multi_logloss: 0.730251\n",
      "[124]\ttraining's multi_logloss: 0.38463\tvalid_1's multi_logloss: 0.730363\n",
      "[125]\ttraining's multi_logloss: 0.38333\tvalid_1's multi_logloss: 0.730484\n",
      "[126]\ttraining's multi_logloss: 0.381726\tvalid_1's multi_logloss: 0.730041\n",
      "[127]\ttraining's multi_logloss: 0.380511\tvalid_1's multi_logloss: 0.730123\n",
      "[128]\ttraining's multi_logloss: 0.378901\tvalid_1's multi_logloss: 0.730239\n",
      "[129]\ttraining's multi_logloss: 0.377102\tvalid_1's multi_logloss: 0.729951\n",
      "[130]\ttraining's multi_logloss: 0.375686\tvalid_1's multi_logloss: 0.730595\n",
      "[131]\ttraining's multi_logloss: 0.374303\tvalid_1's multi_logloss: 0.732153\n",
      "[132]\ttraining's multi_logloss: 0.372939\tvalid_1's multi_logloss: 0.732016\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's multi_logloss: 0.421508\tvalid_1's multi_logloss: 0.724324\n",
      "[1]\ttraining's multi_logloss: 0.856497\tvalid_1's multi_logloss: 0.865687\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.833141\tvalid_1's multi_logloss: 0.850022\n",
      "[3]\ttraining's multi_logloss: 0.813507\tvalid_1's multi_logloss: 0.838161\n",
      "[4]\ttraining's multi_logloss: 0.796911\tvalid_1's multi_logloss: 0.828568\n",
      "[5]\ttraining's multi_logloss: 0.781741\tvalid_1's multi_logloss: 0.822194\n",
      "[6]\ttraining's multi_logloss: 0.768027\tvalid_1's multi_logloss: 0.815358\n",
      "[7]\ttraining's multi_logloss: 0.7555\tvalid_1's multi_logloss: 0.809958\n",
      "[8]\ttraining's multi_logloss: 0.745038\tvalid_1's multi_logloss: 0.805199\n",
      "[9]\ttraining's multi_logloss: 0.73479\tvalid_1's multi_logloss: 0.800693\n",
      "[10]\ttraining's multi_logloss: 0.725655\tvalid_1's multi_logloss: 0.797582\n",
      "[11]\ttraining's multi_logloss: 0.715896\tvalid_1's multi_logloss: 0.793593\n",
      "[12]\ttraining's multi_logloss: 0.707258\tvalid_1's multi_logloss: 0.79079\n",
      "[13]\ttraining's multi_logloss: 0.699888\tvalid_1's multi_logloss: 0.788709\n",
      "[14]\ttraining's multi_logloss: 0.69336\tvalid_1's multi_logloss: 0.786994\n",
      "[15]\ttraining's multi_logloss: 0.687515\tvalid_1's multi_logloss: 0.78562\n",
      "[16]\ttraining's multi_logloss: 0.680988\tvalid_1's multi_logloss: 0.782311\n",
      "[17]\ttraining's multi_logloss: 0.674981\tvalid_1's multi_logloss: 0.781705\n",
      "[18]\ttraining's multi_logloss: 0.669582\tvalid_1's multi_logloss: 0.780386\n",
      "[19]\ttraining's multi_logloss: 0.664378\tvalid_1's multi_logloss: 0.777769\n",
      "[20]\ttraining's multi_logloss: 0.659861\tvalid_1's multi_logloss: 0.776305\n",
      "[21]\ttraining's multi_logloss: 0.655076\tvalid_1's multi_logloss: 0.776537\n",
      "[22]\ttraining's multi_logloss: 0.650402\tvalid_1's multi_logloss: 0.77659\n",
      "[23]\ttraining's multi_logloss: 0.645442\tvalid_1's multi_logloss: 0.77612\n",
      "[24]\ttraining's multi_logloss: 0.640822\tvalid_1's multi_logloss: 0.776302\n",
      "[25]\ttraining's multi_logloss: 0.636008\tvalid_1's multi_logloss: 0.776145\n",
      "[26]\ttraining's multi_logloss: 0.631288\tvalid_1's multi_logloss: 0.77684\n",
      "[27]\ttraining's multi_logloss: 0.626706\tvalid_1's multi_logloss: 0.77674\n",
      "[28]\ttraining's multi_logloss: 0.621054\tvalid_1's multi_logloss: 0.775534\n",
      "[29]\ttraining's multi_logloss: 0.61702\tvalid_1's multi_logloss: 0.77471\n",
      "[30]\ttraining's multi_logloss: 0.612388\tvalid_1's multi_logloss: 0.77463\n",
      "[31]\ttraining's multi_logloss: 0.60867\tvalid_1's multi_logloss: 0.77562\n",
      "[32]\ttraining's multi_logloss: 0.604721\tvalid_1's multi_logloss: 0.775243\n",
      "[33]\ttraining's multi_logloss: 0.600454\tvalid_1's multi_logloss: 0.772752\n",
      "[34]\ttraining's multi_logloss: 0.596463\tvalid_1's multi_logloss: 0.774029\n",
      "[35]\ttraining's multi_logloss: 0.59233\tvalid_1's multi_logloss: 0.774063\n",
      "[36]\ttraining's multi_logloss: 0.588496\tvalid_1's multi_logloss: 0.77365\n",
      "[37]\ttraining's multi_logloss: 0.585716\tvalid_1's multi_logloss: 0.773289\n",
      "[38]\ttraining's multi_logloss: 0.58224\tvalid_1's multi_logloss: 0.773921\n",
      "[39]\ttraining's multi_logloss: 0.579647\tvalid_1's multi_logloss: 0.774659\n",
      "[40]\ttraining's multi_logloss: 0.576279\tvalid_1's multi_logloss: 0.774982\n",
      "[41]\ttraining's multi_logloss: 0.572116\tvalid_1's multi_logloss: 0.774554\n",
      "[42]\ttraining's multi_logloss: 0.568395\tvalid_1's multi_logloss: 0.774607\n",
      "[43]\ttraining's multi_logloss: 0.564817\tvalid_1's multi_logloss: 0.774721\n",
      "[44]\ttraining's multi_logloss: 0.562238\tvalid_1's multi_logloss: 0.774599\n",
      "[45]\ttraining's multi_logloss: 0.559094\tvalid_1's multi_logloss: 0.774593\n",
      "[46]\ttraining's multi_logloss: 0.555991\tvalid_1's multi_logloss: 0.774862\n",
      "[47]\ttraining's multi_logloss: 0.552658\tvalid_1's multi_logloss: 0.774661\n",
      "[48]\ttraining's multi_logloss: 0.549281\tvalid_1's multi_logloss: 0.774258\n",
      "[49]\ttraining's multi_logloss: 0.545858\tvalid_1's multi_logloss: 0.774581\n",
      "[50]\ttraining's multi_logloss: 0.542606\tvalid_1's multi_logloss: 0.774438\n",
      "[51]\ttraining's multi_logloss: 0.539657\tvalid_1's multi_logloss: 0.775738\n",
      "[52]\ttraining's multi_logloss: 0.536444\tvalid_1's multi_logloss: 0.775415\n",
      "[53]\ttraining's multi_logloss: 0.533201\tvalid_1's multi_logloss: 0.776182\n",
      "[54]\ttraining's multi_logloss: 0.529903\tvalid_1's multi_logloss: 0.776187\n",
      "[55]\ttraining's multi_logloss: 0.526496\tvalid_1's multi_logloss: 0.776843\n",
      "[56]\ttraining's multi_logloss: 0.523897\tvalid_1's multi_logloss: 0.776787\n",
      "[57]\ttraining's multi_logloss: 0.521754\tvalid_1's multi_logloss: 0.776318\n",
      "[58]\ttraining's multi_logloss: 0.518764\tvalid_1's multi_logloss: 0.77569\n",
      "[59]\ttraining's multi_logloss: 0.516528\tvalid_1's multi_logloss: 0.776026\n",
      "[60]\ttraining's multi_logloss: 0.514063\tvalid_1's multi_logloss: 0.775841\n",
      "[61]\ttraining's multi_logloss: 0.511501\tvalid_1's multi_logloss: 0.776642\n",
      "[62]\ttraining's multi_logloss: 0.508701\tvalid_1's multi_logloss: 0.776708\n",
      "[63]\ttraining's multi_logloss: 0.506348\tvalid_1's multi_logloss: 0.776286\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's multi_logloss: 0.600454\tvalid_1's multi_logloss: 0.772752\n",
      "[1]\ttraining's multi_logloss: 0.856588\tvalid_1's multi_logloss: 0.861627\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttraining's multi_logloss: 0.832814\tvalid_1's multi_logloss: 0.844246\n",
      "[3]\ttraining's multi_logloss: 0.813603\tvalid_1's multi_logloss: 0.832335\n",
      "[4]\ttraining's multi_logloss: 0.797233\tvalid_1's multi_logloss: 0.821042\n",
      "[5]\ttraining's multi_logloss: 0.782527\tvalid_1's multi_logloss: 0.811279\n",
      "[6]\ttraining's multi_logloss: 0.769854\tvalid_1's multi_logloss: 0.803037\n",
      "[7]\ttraining's multi_logloss: 0.757045\tvalid_1's multi_logloss: 0.796903\n",
      "[8]\ttraining's multi_logloss: 0.745824\tvalid_1's multi_logloss: 0.792028\n",
      "[9]\ttraining's multi_logloss: 0.735465\tvalid_1's multi_logloss: 0.78738\n",
      "[10]\ttraining's multi_logloss: 0.726026\tvalid_1's multi_logloss: 0.784709\n",
      "[11]\ttraining's multi_logloss: 0.716915\tvalid_1's multi_logloss: 0.781272\n",
      "[12]\ttraining's multi_logloss: 0.707899\tvalid_1's multi_logloss: 0.776588\n",
      "[13]\ttraining's multi_logloss: 0.70069\tvalid_1's multi_logloss: 0.773091\n",
      "[14]\ttraining's multi_logloss: 0.693631\tvalid_1's multi_logloss: 0.77099\n",
      "[15]\ttraining's multi_logloss: 0.686086\tvalid_1's multi_logloss: 0.769222\n",
      "[16]\ttraining's multi_logloss: 0.679365\tvalid_1's multi_logloss: 0.76837\n",
      "[17]\ttraining's multi_logloss: 0.673887\tvalid_1's multi_logloss: 0.768229\n",
      "[18]\ttraining's multi_logloss: 0.668804\tvalid_1's multi_logloss: 0.767396\n",
      "[19]\ttraining's multi_logloss: 0.662275\tvalid_1's multi_logloss: 0.763817\n",
      "[20]\ttraining's multi_logloss: 0.656221\tvalid_1's multi_logloss: 0.762587\n",
      "[21]\ttraining's multi_logloss: 0.651194\tvalid_1's multi_logloss: 0.760782\n",
      "[22]\ttraining's multi_logloss: 0.645638\tvalid_1's multi_logloss: 0.759593\n",
      "[23]\ttraining's multi_logloss: 0.640416\tvalid_1's multi_logloss: 0.757674\n",
      "[24]\ttraining's multi_logloss: 0.636103\tvalid_1's multi_logloss: 0.757127\n",
      "[25]\ttraining's multi_logloss: 0.631598\tvalid_1's multi_logloss: 0.757384\n",
      "[26]\ttraining's multi_logloss: 0.627271\tvalid_1's multi_logloss: 0.756313\n",
      "[27]\ttraining's multi_logloss: 0.622783\tvalid_1's multi_logloss: 0.75473\n",
      "[28]\ttraining's multi_logloss: 0.618339\tvalid_1's multi_logloss: 0.754552\n",
      "[29]\ttraining's multi_logloss: 0.613853\tvalid_1's multi_logloss: 0.75422\n",
      "[30]\ttraining's multi_logloss: 0.60978\tvalid_1's multi_logloss: 0.753667\n",
      "[31]\ttraining's multi_logloss: 0.605437\tvalid_1's multi_logloss: 0.754005\n",
      "[32]\ttraining's multi_logloss: 0.601882\tvalid_1's multi_logloss: 0.754013\n",
      "[33]\ttraining's multi_logloss: 0.598123\tvalid_1's multi_logloss: 0.753125\n",
      "[34]\ttraining's multi_logloss: 0.59441\tvalid_1's multi_logloss: 0.751565\n",
      "[35]\ttraining's multi_logloss: 0.590787\tvalid_1's multi_logloss: 0.751059\n",
      "[36]\ttraining's multi_logloss: 0.5873\tvalid_1's multi_logloss: 0.750461\n",
      "[37]\ttraining's multi_logloss: 0.583341\tvalid_1's multi_logloss: 0.748169\n",
      "[38]\ttraining's multi_logloss: 0.579803\tvalid_1's multi_logloss: 0.748312\n",
      "[39]\ttraining's multi_logloss: 0.576121\tvalid_1's multi_logloss: 0.748198\n",
      "[40]\ttraining's multi_logloss: 0.572878\tvalid_1's multi_logloss: 0.747197\n",
      "[41]\ttraining's multi_logloss: 0.569179\tvalid_1's multi_logloss: 0.745031\n",
      "[42]\ttraining's multi_logloss: 0.565824\tvalid_1's multi_logloss: 0.743148\n",
      "[43]\ttraining's multi_logloss: 0.56294\tvalid_1's multi_logloss: 0.743607\n",
      "[44]\ttraining's multi_logloss: 0.559137\tvalid_1's multi_logloss: 0.742433\n",
      "[45]\ttraining's multi_logloss: 0.555709\tvalid_1's multi_logloss: 0.741918\n",
      "[46]\ttraining's multi_logloss: 0.552578\tvalid_1's multi_logloss: 0.741751\n",
      "[47]\ttraining's multi_logloss: 0.549591\tvalid_1's multi_logloss: 0.740942\n",
      "[48]\ttraining's multi_logloss: 0.546429\tvalid_1's multi_logloss: 0.740939\n",
      "[49]\ttraining's multi_logloss: 0.544\tvalid_1's multi_logloss: 0.740691\n",
      "[50]\ttraining's multi_logloss: 0.541056\tvalid_1's multi_logloss: 0.740971\n",
      "[51]\ttraining's multi_logloss: 0.537784\tvalid_1's multi_logloss: 0.741328\n",
      "[52]\ttraining's multi_logloss: 0.53482\tvalid_1's multi_logloss: 0.74097\n",
      "[53]\ttraining's multi_logloss: 0.532117\tvalid_1's multi_logloss: 0.741949\n",
      "[54]\ttraining's multi_logloss: 0.528818\tvalid_1's multi_logloss: 0.741677\n",
      "[55]\ttraining's multi_logloss: 0.525849\tvalid_1's multi_logloss: 0.741859\n",
      "[56]\ttraining's multi_logloss: 0.523121\tvalid_1's multi_logloss: 0.741759\n",
      "[57]\ttraining's multi_logloss: 0.520547\tvalid_1's multi_logloss: 0.74235\n",
      "[58]\ttraining's multi_logloss: 0.518222\tvalid_1's multi_logloss: 0.743261\n",
      "[59]\ttraining's multi_logloss: 0.515526\tvalid_1's multi_logloss: 0.743836\n",
      "[60]\ttraining's multi_logloss: 0.512599\tvalid_1's multi_logloss: 0.743559\n",
      "[61]\ttraining's multi_logloss: 0.510668\tvalid_1's multi_logloss: 0.743185\n",
      "[62]\ttraining's multi_logloss: 0.508679\tvalid_1's multi_logloss: 0.74281\n",
      "[63]\ttraining's multi_logloss: 0.505939\tvalid_1's multi_logloss: 0.742267\n",
      "[64]\ttraining's multi_logloss: 0.503468\tvalid_1's multi_logloss: 0.741369\n",
      "[65]\ttraining's multi_logloss: 0.50086\tvalid_1's multi_logloss: 0.741006\n",
      "[66]\ttraining's multi_logloss: 0.498687\tvalid_1's multi_logloss: 0.74143\n",
      "[67]\ttraining's multi_logloss: 0.496337\tvalid_1's multi_logloss: 0.741697\n",
      "[68]\ttraining's multi_logloss: 0.493944\tvalid_1's multi_logloss: 0.741232\n",
      "[69]\ttraining's multi_logloss: 0.491118\tvalid_1's multi_logloss: 0.740503\n",
      "[70]\ttraining's multi_logloss: 0.488693\tvalid_1's multi_logloss: 0.740932\n",
      "[71]\ttraining's multi_logloss: 0.486377\tvalid_1's multi_logloss: 0.741187\n",
      "[72]\ttraining's multi_logloss: 0.484132\tvalid_1's multi_logloss: 0.74064\n",
      "[73]\ttraining's multi_logloss: 0.482138\tvalid_1's multi_logloss: 0.74084\n",
      "[74]\ttraining's multi_logloss: 0.479523\tvalid_1's multi_logloss: 0.740027\n",
      "[75]\ttraining's multi_logloss: 0.477366\tvalid_1's multi_logloss: 0.739418\n",
      "[76]\ttraining's multi_logloss: 0.474823\tvalid_1's multi_logloss: 0.739733\n",
      "[77]\ttraining's multi_logloss: 0.472723\tvalid_1's multi_logloss: 0.73955\n",
      "[78]\ttraining's multi_logloss: 0.470671\tvalid_1's multi_logloss: 0.74028\n",
      "[79]\ttraining's multi_logloss: 0.467926\tvalid_1's multi_logloss: 0.740859\n",
      "[80]\ttraining's multi_logloss: 0.465807\tvalid_1's multi_logloss: 0.740572\n",
      "[81]\ttraining's multi_logloss: 0.463691\tvalid_1's multi_logloss: 0.740423\n",
      "[82]\ttraining's multi_logloss: 0.461732\tvalid_1's multi_logloss: 0.740427\n",
      "[83]\ttraining's multi_logloss: 0.459232\tvalid_1's multi_logloss: 0.74082\n",
      "[84]\ttraining's multi_logloss: 0.457091\tvalid_1's multi_logloss: 0.740671\n",
      "[85]\ttraining's multi_logloss: 0.455089\tvalid_1's multi_logloss: 0.741606\n",
      "[86]\ttraining's multi_logloss: 0.453123\tvalid_1's multi_logloss: 0.74136\n",
      "[87]\ttraining's multi_logloss: 0.451026\tvalid_1's multi_logloss: 0.740773\n",
      "[88]\ttraining's multi_logloss: 0.448597\tvalid_1's multi_logloss: 0.740974\n",
      "[89]\ttraining's multi_logloss: 0.446545\tvalid_1's multi_logloss: 0.741481\n",
      "[90]\ttraining's multi_logloss: 0.444663\tvalid_1's multi_logloss: 0.74162\n",
      "[91]\ttraining's multi_logloss: 0.442657\tvalid_1's multi_logloss: 0.740882\n",
      "[92]\ttraining's multi_logloss: 0.440606\tvalid_1's multi_logloss: 0.741437\n",
      "[93]\ttraining's multi_logloss: 0.438874\tvalid_1's multi_logloss: 0.742312\n",
      "[94]\ttraining's multi_logloss: 0.437113\tvalid_1's multi_logloss: 0.743095\n",
      "[95]\ttraining's multi_logloss: 0.435026\tvalid_1's multi_logloss: 0.742897\n",
      "[96]\ttraining's multi_logloss: 0.43308\tvalid_1's multi_logloss: 0.742458\n",
      "[97]\ttraining's multi_logloss: 0.431557\tvalid_1's multi_logloss: 0.743028\n",
      "[98]\ttraining's multi_logloss: 0.429982\tvalid_1's multi_logloss: 0.743731\n",
      "[99]\ttraining's multi_logloss: 0.428339\tvalid_1's multi_logloss: 0.742551\n",
      "[100]\ttraining's multi_logloss: 0.426198\tvalid_1's multi_logloss: 0.742597\n",
      "[101]\ttraining's multi_logloss: 0.424174\tvalid_1's multi_logloss: 0.743234\n",
      "[102]\ttraining's multi_logloss: 0.422496\tvalid_1's multi_logloss: 0.743024\n",
      "[103]\ttraining's multi_logloss: 0.420604\tvalid_1's multi_logloss: 0.742958\n",
      "[104]\ttraining's multi_logloss: 0.418948\tvalid_1's multi_logloss: 0.742972\n",
      "[105]\ttraining's multi_logloss: 0.41738\tvalid_1's multi_logloss: 0.742992\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's multi_logloss: 0.477366\tvalid_1's multi_logloss: 0.739418\n",
      "[1]\ttraining's multi_logloss: 0.854697\tvalid_1's multi_logloss: 0.868832\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.830218\tvalid_1's multi_logloss: 0.856152\n",
      "[3]\ttraining's multi_logloss: 0.809623\tvalid_1's multi_logloss: 0.844906\n",
      "[4]\ttraining's multi_logloss: 0.793002\tvalid_1's multi_logloss: 0.837226\n",
      "[5]\ttraining's multi_logloss: 0.777746\tvalid_1's multi_logloss: 0.831889\n",
      "[6]\ttraining's multi_logloss: 0.764901\tvalid_1's multi_logloss: 0.827088\n",
      "[7]\ttraining's multi_logloss: 0.752625\tvalid_1's multi_logloss: 0.822693\n",
      "[8]\ttraining's multi_logloss: 0.741394\tvalid_1's multi_logloss: 0.818151\n",
      "[9]\ttraining's multi_logloss: 0.731023\tvalid_1's multi_logloss: 0.813982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's multi_logloss: 0.721375\tvalid_1's multi_logloss: 0.810012\n",
      "[11]\ttraining's multi_logloss: 0.71261\tvalid_1's multi_logloss: 0.80824\n",
      "[12]\ttraining's multi_logloss: 0.704916\tvalid_1's multi_logloss: 0.805875\n",
      "[13]\ttraining's multi_logloss: 0.696898\tvalid_1's multi_logloss: 0.801725\n",
      "[14]\ttraining's multi_logloss: 0.689554\tvalid_1's multi_logloss: 0.798247\n",
      "[15]\ttraining's multi_logloss: 0.683249\tvalid_1's multi_logloss: 0.795942\n",
      "[16]\ttraining's multi_logloss: 0.67665\tvalid_1's multi_logloss: 0.794022\n",
      "[17]\ttraining's multi_logloss: 0.670218\tvalid_1's multi_logloss: 0.791469\n",
      "[18]\ttraining's multi_logloss: 0.663907\tvalid_1's multi_logloss: 0.790191\n",
      "[19]\ttraining's multi_logloss: 0.659052\tvalid_1's multi_logloss: 0.789466\n",
      "[20]\ttraining's multi_logloss: 0.653527\tvalid_1's multi_logloss: 0.787666\n",
      "[21]\ttraining's multi_logloss: 0.648538\tvalid_1's multi_logloss: 0.787617\n",
      "[22]\ttraining's multi_logloss: 0.643498\tvalid_1's multi_logloss: 0.785117\n",
      "[23]\ttraining's multi_logloss: 0.639134\tvalid_1's multi_logloss: 0.783677\n",
      "[24]\ttraining's multi_logloss: 0.634314\tvalid_1's multi_logloss: 0.783197\n",
      "[25]\ttraining's multi_logloss: 0.630092\tvalid_1's multi_logloss: 0.782564\n",
      "[26]\ttraining's multi_logloss: 0.625453\tvalid_1's multi_logloss: 0.781816\n",
      "[27]\ttraining's multi_logloss: 0.621324\tvalid_1's multi_logloss: 0.781419\n",
      "[28]\ttraining's multi_logloss: 0.617748\tvalid_1's multi_logloss: 0.780588\n",
      "[29]\ttraining's multi_logloss: 0.614005\tvalid_1's multi_logloss: 0.779593\n",
      "[30]\ttraining's multi_logloss: 0.609884\tvalid_1's multi_logloss: 0.779607\n",
      "[31]\ttraining's multi_logloss: 0.60548\tvalid_1's multi_logloss: 0.778633\n",
      "[32]\ttraining's multi_logloss: 0.601753\tvalid_1's multi_logloss: 0.777765\n",
      "[33]\ttraining's multi_logloss: 0.597846\tvalid_1's multi_logloss: 0.775724\n",
      "[34]\ttraining's multi_logloss: 0.594183\tvalid_1's multi_logloss: 0.776136\n",
      "[35]\ttraining's multi_logloss: 0.59002\tvalid_1's multi_logloss: 0.776438\n",
      "[36]\ttraining's multi_logloss: 0.586407\tvalid_1's multi_logloss: 0.775542\n",
      "[37]\ttraining's multi_logloss: 0.582829\tvalid_1's multi_logloss: 0.775911\n",
      "[38]\ttraining's multi_logloss: 0.579458\tvalid_1's multi_logloss: 0.77541\n",
      "[39]\ttraining's multi_logloss: 0.575529\tvalid_1's multi_logloss: 0.774584\n",
      "[40]\ttraining's multi_logloss: 0.571635\tvalid_1's multi_logloss: 0.77294\n",
      "[41]\ttraining's multi_logloss: 0.568316\tvalid_1's multi_logloss: 0.772595\n",
      "[42]\ttraining's multi_logloss: 0.563779\tvalid_1's multi_logloss: 0.772\n",
      "[43]\ttraining's multi_logloss: 0.560375\tvalid_1's multi_logloss: 0.77139\n",
      "[44]\ttraining's multi_logloss: 0.55746\tvalid_1's multi_logloss: 0.770848\n",
      "[45]\ttraining's multi_logloss: 0.554391\tvalid_1's multi_logloss: 0.770594\n",
      "[46]\ttraining's multi_logloss: 0.550689\tvalid_1's multi_logloss: 0.77107\n",
      "[47]\ttraining's multi_logloss: 0.547965\tvalid_1's multi_logloss: 0.770732\n",
      "[48]\ttraining's multi_logloss: 0.545069\tvalid_1's multi_logloss: 0.771144\n",
      "[49]\ttraining's multi_logloss: 0.542217\tvalid_1's multi_logloss: 0.77191\n",
      "[50]\ttraining's multi_logloss: 0.539385\tvalid_1's multi_logloss: 0.771067\n",
      "[51]\ttraining's multi_logloss: 0.536283\tvalid_1's multi_logloss: 0.771573\n",
      "[52]\ttraining's multi_logloss: 0.533102\tvalid_1's multi_logloss: 0.771203\n",
      "[53]\ttraining's multi_logloss: 0.530298\tvalid_1's multi_logloss: 0.770219\n",
      "[54]\ttraining's multi_logloss: 0.527386\tvalid_1's multi_logloss: 0.769363\n",
      "[55]\ttraining's multi_logloss: 0.524818\tvalid_1's multi_logloss: 0.769908\n",
      "[56]\ttraining's multi_logloss: 0.522322\tvalid_1's multi_logloss: 0.770758\n",
      "[57]\ttraining's multi_logloss: 0.51948\tvalid_1's multi_logloss: 0.770579\n",
      "[58]\ttraining's multi_logloss: 0.516317\tvalid_1's multi_logloss: 0.768995\n",
      "[59]\ttraining's multi_logloss: 0.513575\tvalid_1's multi_logloss: 0.768287\n",
      "[60]\ttraining's multi_logloss: 0.51103\tvalid_1's multi_logloss: 0.767979\n",
      "[61]\ttraining's multi_logloss: 0.507877\tvalid_1's multi_logloss: 0.766847\n",
      "[62]\ttraining's multi_logloss: 0.505512\tvalid_1's multi_logloss: 0.766539\n",
      "[63]\ttraining's multi_logloss: 0.50297\tvalid_1's multi_logloss: 0.76654\n",
      "[64]\ttraining's multi_logloss: 0.500644\tvalid_1's multi_logloss: 0.765997\n",
      "[65]\ttraining's multi_logloss: 0.498521\tvalid_1's multi_logloss: 0.765823\n",
      "[66]\ttraining's multi_logloss: 0.495519\tvalid_1's multi_logloss: 0.76641\n",
      "[67]\ttraining's multi_logloss: 0.493027\tvalid_1's multi_logloss: 0.766684\n",
      "[68]\ttraining's multi_logloss: 0.490162\tvalid_1's multi_logloss: 0.767639\n",
      "[69]\ttraining's multi_logloss: 0.487733\tvalid_1's multi_logloss: 0.76685\n",
      "[70]\ttraining's multi_logloss: 0.485075\tvalid_1's multi_logloss: 0.766413\n",
      "[71]\ttraining's multi_logloss: 0.48278\tvalid_1's multi_logloss: 0.765901\n",
      "[72]\ttraining's multi_logloss: 0.48076\tvalid_1's multi_logloss: 0.766308\n",
      "[73]\ttraining's multi_logloss: 0.478479\tvalid_1's multi_logloss: 0.766868\n",
      "[74]\ttraining's multi_logloss: 0.476536\tvalid_1's multi_logloss: 0.766788\n",
      "[75]\ttraining's multi_logloss: 0.474139\tvalid_1's multi_logloss: 0.767312\n",
      "[76]\ttraining's multi_logloss: 0.471074\tvalid_1's multi_logloss: 0.766789\n",
      "[77]\ttraining's multi_logloss: 0.469092\tvalid_1's multi_logloss: 0.767947\n",
      "[78]\ttraining's multi_logloss: 0.466915\tvalid_1's multi_logloss: 0.767854\n",
      "[79]\ttraining's multi_logloss: 0.465185\tvalid_1's multi_logloss: 0.768268\n",
      "[80]\ttraining's multi_logloss: 0.463029\tvalid_1's multi_logloss: 0.768567\n",
      "[81]\ttraining's multi_logloss: 0.461364\tvalid_1's multi_logloss: 0.768854\n",
      "[82]\ttraining's multi_logloss: 0.459414\tvalid_1's multi_logloss: 0.769405\n",
      "[83]\ttraining's multi_logloss: 0.457001\tvalid_1's multi_logloss: 0.769492\n",
      "[84]\ttraining's multi_logloss: 0.454805\tvalid_1's multi_logloss: 0.76989\n",
      "[85]\ttraining's multi_logloss: 0.452633\tvalid_1's multi_logloss: 0.770727\n",
      "[86]\ttraining's multi_logloss: 0.450466\tvalid_1's multi_logloss: 0.773231\n",
      "[87]\ttraining's multi_logloss: 0.448151\tvalid_1's multi_logloss: 0.773784\n",
      "[88]\ttraining's multi_logloss: 0.445708\tvalid_1's multi_logloss: 0.774319\n",
      "[89]\ttraining's multi_logloss: 0.443993\tvalid_1's multi_logloss: 0.774387\n",
      "[90]\ttraining's multi_logloss: 0.441867\tvalid_1's multi_logloss: 0.774901\n",
      "[91]\ttraining's multi_logloss: 0.43981\tvalid_1's multi_logloss: 0.773666\n",
      "[92]\ttraining's multi_logloss: 0.437556\tvalid_1's multi_logloss: 0.773687\n",
      "[93]\ttraining's multi_logloss: 0.43578\tvalid_1's multi_logloss: 0.775407\n",
      "[94]\ttraining's multi_logloss: 0.433945\tvalid_1's multi_logloss: 0.775226\n",
      "[95]\ttraining's multi_logloss: 0.432035\tvalid_1's multi_logloss: 0.775645\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's multi_logloss: 0.498521\tvalid_1's multi_logloss: 0.765823\n",
      "[1]\ttraining's multi_logloss: 0.85766\tvalid_1's multi_logloss: 0.864011\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.833485\tvalid_1's multi_logloss: 0.847864\n",
      "[3]\ttraining's multi_logloss: 0.814777\tvalid_1's multi_logloss: 0.835387\n",
      "[4]\ttraining's multi_logloss: 0.797778\tvalid_1's multi_logloss: 0.826429\n",
      "[5]\ttraining's multi_logloss: 0.78237\tvalid_1's multi_logloss: 0.816433\n",
      "[6]\ttraining's multi_logloss: 0.769059\tvalid_1's multi_logloss: 0.808646\n",
      "[7]\ttraining's multi_logloss: 0.757375\tvalid_1's multi_logloss: 0.802182\n",
      "[8]\ttraining's multi_logloss: 0.747067\tvalid_1's multi_logloss: 0.796315\n",
      "[9]\ttraining's multi_logloss: 0.73674\tvalid_1's multi_logloss: 0.790775\n",
      "[10]\ttraining's multi_logloss: 0.727689\tvalid_1's multi_logloss: 0.785397\n",
      "[11]\ttraining's multi_logloss: 0.719351\tvalid_1's multi_logloss: 0.780093\n",
      "[12]\ttraining's multi_logloss: 0.710725\tvalid_1's multi_logloss: 0.776811\n",
      "[13]\ttraining's multi_logloss: 0.703397\tvalid_1's multi_logloss: 0.773072\n",
      "[14]\ttraining's multi_logloss: 0.697195\tvalid_1's multi_logloss: 0.771789\n",
      "[15]\ttraining's multi_logloss: 0.690564\tvalid_1's multi_logloss: 0.769427\n",
      "[16]\ttraining's multi_logloss: 0.684585\tvalid_1's multi_logloss: 0.766858\n",
      "[17]\ttraining's multi_logloss: 0.678133\tvalid_1's multi_logloss: 0.763491\n",
      "[18]\ttraining's multi_logloss: 0.672144\tvalid_1's multi_logloss: 0.762128\n",
      "[19]\ttraining's multi_logloss: 0.666756\tvalid_1's multi_logloss: 0.759205\n",
      "[20]\ttraining's multi_logloss: 0.66206\tvalid_1's multi_logloss: 0.756971\n",
      "[21]\ttraining's multi_logloss: 0.656979\tvalid_1's multi_logloss: 0.756819\n",
      "[22]\ttraining's multi_logloss: 0.65245\tvalid_1's multi_logloss: 0.75497\n",
      "[23]\ttraining's multi_logloss: 0.647492\tvalid_1's multi_logloss: 0.751617\n",
      "[24]\ttraining's multi_logloss: 0.64247\tvalid_1's multi_logloss: 0.750373\n",
      "[25]\ttraining's multi_logloss: 0.637362\tvalid_1's multi_logloss: 0.749814\n",
      "[26]\ttraining's multi_logloss: 0.632888\tvalid_1's multi_logloss: 0.747792\n",
      "[27]\ttraining's multi_logloss: 0.628318\tvalid_1's multi_logloss: 0.745658\n",
      "[28]\ttraining's multi_logloss: 0.624256\tvalid_1's multi_logloss: 0.745201\n",
      "[29]\ttraining's multi_logloss: 0.619802\tvalid_1's multi_logloss: 0.743324\n",
      "[30]\ttraining's multi_logloss: 0.615839\tvalid_1's multi_logloss: 0.742205\n",
      "[31]\ttraining's multi_logloss: 0.612244\tvalid_1's multi_logloss: 0.740732\n",
      "[32]\ttraining's multi_logloss: 0.607627\tvalid_1's multi_logloss: 0.739642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttraining's multi_logloss: 0.602399\tvalid_1's multi_logloss: 0.738586\n",
      "[34]\ttraining's multi_logloss: 0.59833\tvalid_1's multi_logloss: 0.735843\n",
      "[35]\ttraining's multi_logloss: 0.593799\tvalid_1's multi_logloss: 0.735775\n",
      "[36]\ttraining's multi_logloss: 0.590132\tvalid_1's multi_logloss: 0.736099\n",
      "[37]\ttraining's multi_logloss: 0.586532\tvalid_1's multi_logloss: 0.736244\n",
      "[38]\ttraining's multi_logloss: 0.582194\tvalid_1's multi_logloss: 0.737594\n",
      "[39]\ttraining's multi_logloss: 0.578927\tvalid_1's multi_logloss: 0.736826\n",
      "[40]\ttraining's multi_logloss: 0.574719\tvalid_1's multi_logloss: 0.736032\n",
      "[41]\ttraining's multi_logloss: 0.571529\tvalid_1's multi_logloss: 0.735165\n",
      "[42]\ttraining's multi_logloss: 0.568768\tvalid_1's multi_logloss: 0.735277\n",
      "[43]\ttraining's multi_logloss: 0.565082\tvalid_1's multi_logloss: 0.734914\n",
      "[44]\ttraining's multi_logloss: 0.561564\tvalid_1's multi_logloss: 0.73531\n",
      "[45]\ttraining's multi_logloss: 0.559286\tvalid_1's multi_logloss: 0.734856\n",
      "[46]\ttraining's multi_logloss: 0.556299\tvalid_1's multi_logloss: 0.734672\n",
      "[47]\ttraining's multi_logloss: 0.552916\tvalid_1's multi_logloss: 0.734862\n",
      "[48]\ttraining's multi_logloss: 0.550045\tvalid_1's multi_logloss: 0.734729\n",
      "[49]\ttraining's multi_logloss: 0.546997\tvalid_1's multi_logloss: 0.734397\n",
      "[50]\ttraining's multi_logloss: 0.54384\tvalid_1's multi_logloss: 0.734132\n",
      "[51]\ttraining's multi_logloss: 0.541017\tvalid_1's multi_logloss: 0.734286\n",
      "[52]\ttraining's multi_logloss: 0.537386\tvalid_1's multi_logloss: 0.734262\n",
      "[53]\ttraining's multi_logloss: 0.534362\tvalid_1's multi_logloss: 0.734629\n",
      "[54]\ttraining's multi_logloss: 0.531085\tvalid_1's multi_logloss: 0.734967\n",
      "[55]\ttraining's multi_logloss: 0.528034\tvalid_1's multi_logloss: 0.734807\n",
      "[56]\ttraining's multi_logloss: 0.525132\tvalid_1's multi_logloss: 0.73407\n",
      "[57]\ttraining's multi_logloss: 0.522354\tvalid_1's multi_logloss: 0.732608\n",
      "[58]\ttraining's multi_logloss: 0.519484\tvalid_1's multi_logloss: 0.732293\n",
      "[59]\ttraining's multi_logloss: 0.516709\tvalid_1's multi_logloss: 0.733194\n",
      "[60]\ttraining's multi_logloss: 0.514034\tvalid_1's multi_logloss: 0.733474\n",
      "[61]\ttraining's multi_logloss: 0.511338\tvalid_1's multi_logloss: 0.733166\n",
      "[62]\ttraining's multi_logloss: 0.50896\tvalid_1's multi_logloss: 0.73376\n",
      "[63]\ttraining's multi_logloss: 0.506171\tvalid_1's multi_logloss: 0.733508\n",
      "[64]\ttraining's multi_logloss: 0.503908\tvalid_1's multi_logloss: 0.733553\n",
      "[65]\ttraining's multi_logloss: 0.501309\tvalid_1's multi_logloss: 0.732766\n",
      "[66]\ttraining's multi_logloss: 0.498549\tvalid_1's multi_logloss: 0.732502\n",
      "[67]\ttraining's multi_logloss: 0.495779\tvalid_1's multi_logloss: 0.732011\n",
      "[68]\ttraining's multi_logloss: 0.493336\tvalid_1's multi_logloss: 0.732016\n",
      "[69]\ttraining's multi_logloss: 0.491133\tvalid_1's multi_logloss: 0.732386\n",
      "[70]\ttraining's multi_logloss: 0.488722\tvalid_1's multi_logloss: 0.732008\n",
      "[71]\ttraining's multi_logloss: 0.486032\tvalid_1's multi_logloss: 0.731816\n",
      "[72]\ttraining's multi_logloss: 0.483708\tvalid_1's multi_logloss: 0.732784\n",
      "[73]\ttraining's multi_logloss: 0.481247\tvalid_1's multi_logloss: 0.73337\n",
      "[74]\ttraining's multi_logloss: 0.479245\tvalid_1's multi_logloss: 0.733074\n",
      "[75]\ttraining's multi_logloss: 0.477219\tvalid_1's multi_logloss: 0.732546\n",
      "[76]\ttraining's multi_logloss: 0.474972\tvalid_1's multi_logloss: 0.732215\n",
      "[77]\ttraining's multi_logloss: 0.472683\tvalid_1's multi_logloss: 0.731912\n",
      "[78]\ttraining's multi_logloss: 0.470313\tvalid_1's multi_logloss: 0.732141\n",
      "[79]\ttraining's multi_logloss: 0.468253\tvalid_1's multi_logloss: 0.732696\n",
      "[80]\ttraining's multi_logloss: 0.466451\tvalid_1's multi_logloss: 0.732007\n",
      "[81]\ttraining's multi_logloss: 0.46443\tvalid_1's multi_logloss: 0.731631\n",
      "[82]\ttraining's multi_logloss: 0.46214\tvalid_1's multi_logloss: 0.732239\n",
      "[83]\ttraining's multi_logloss: 0.459982\tvalid_1's multi_logloss: 0.732442\n",
      "[84]\ttraining's multi_logloss: 0.457853\tvalid_1's multi_logloss: 0.732767\n",
      "[85]\ttraining's multi_logloss: 0.455628\tvalid_1's multi_logloss: 0.732931\n",
      "[86]\ttraining's multi_logloss: 0.453819\tvalid_1's multi_logloss: 0.731405\n",
      "[87]\ttraining's multi_logloss: 0.451818\tvalid_1's multi_logloss: 0.731183\n",
      "[88]\ttraining's multi_logloss: 0.449813\tvalid_1's multi_logloss: 0.731011\n",
      "[89]\ttraining's multi_logloss: 0.447859\tvalid_1's multi_logloss: 0.732098\n",
      "[90]\ttraining's multi_logloss: 0.446118\tvalid_1's multi_logloss: 0.732175\n",
      "[91]\ttraining's multi_logloss: 0.444154\tvalid_1's multi_logloss: 0.732475\n",
      "[92]\ttraining's multi_logloss: 0.442312\tvalid_1's multi_logloss: 0.732437\n",
      "[93]\ttraining's multi_logloss: 0.440452\tvalid_1's multi_logloss: 0.732417\n",
      "[94]\ttraining's multi_logloss: 0.438376\tvalid_1's multi_logloss: 0.733177\n",
      "[95]\ttraining's multi_logloss: 0.436433\tvalid_1's multi_logloss: 0.733723\n",
      "[96]\ttraining's multi_logloss: 0.434203\tvalid_1's multi_logloss: 0.734209\n",
      "[97]\ttraining's multi_logloss: 0.432538\tvalid_1's multi_logloss: 0.734995\n",
      "[98]\ttraining's multi_logloss: 0.430718\tvalid_1's multi_logloss: 0.734662\n",
      "[99]\ttraining's multi_logloss: 0.428553\tvalid_1's multi_logloss: 0.733767\n",
      "[100]\ttraining's multi_logloss: 0.42679\tvalid_1's multi_logloss: 0.734026\n",
      "[101]\ttraining's multi_logloss: 0.424837\tvalid_1's multi_logloss: 0.73439\n",
      "[102]\ttraining's multi_logloss: 0.423126\tvalid_1's multi_logloss: 0.734413\n",
      "[103]\ttraining's multi_logloss: 0.421169\tvalid_1's multi_logloss: 0.734266\n",
      "[104]\ttraining's multi_logloss: 0.419369\tvalid_1's multi_logloss: 0.734022\n",
      "[105]\ttraining's multi_logloss: 0.417422\tvalid_1's multi_logloss: 0.734246\n",
      "[106]\ttraining's multi_logloss: 0.415632\tvalid_1's multi_logloss: 0.734191\n",
      "[107]\ttraining's multi_logloss: 0.413967\tvalid_1's multi_logloss: 0.734526\n",
      "[108]\ttraining's multi_logloss: 0.412329\tvalid_1's multi_logloss: 0.734208\n",
      "[109]\ttraining's multi_logloss: 0.410586\tvalid_1's multi_logloss: 0.733573\n",
      "[110]\ttraining's multi_logloss: 0.409099\tvalid_1's multi_logloss: 0.732732\n",
      "[111]\ttraining's multi_logloss: 0.407587\tvalid_1's multi_logloss: 0.733494\n",
      "[112]\ttraining's multi_logloss: 0.405806\tvalid_1's multi_logloss: 0.734667\n",
      "[113]\ttraining's multi_logloss: 0.404099\tvalid_1's multi_logloss: 0.73552\n",
      "[114]\ttraining's multi_logloss: 0.402483\tvalid_1's multi_logloss: 0.735993\n",
      "[115]\ttraining's multi_logloss: 0.401008\tvalid_1's multi_logloss: 0.735434\n",
      "[116]\ttraining's multi_logloss: 0.399372\tvalid_1's multi_logloss: 0.73504\n",
      "[117]\ttraining's multi_logloss: 0.397656\tvalid_1's multi_logloss: 0.73514\n",
      "[118]\ttraining's multi_logloss: 0.395682\tvalid_1's multi_logloss: 0.734864\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's multi_logloss: 0.449813\tvalid_1's multi_logloss: 0.731011\n",
      "[1]\ttraining's multi_logloss: 0.855964\tvalid_1's multi_logloss: 0.862928\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.831276\tvalid_1's multi_logloss: 0.841216\n",
      "[3]\ttraining's multi_logloss: 0.813543\tvalid_1's multi_logloss: 0.825277\n",
      "[4]\ttraining's multi_logloss: 0.797436\tvalid_1's multi_logloss: 0.814121\n",
      "[5]\ttraining's multi_logloss: 0.783383\tvalid_1's multi_logloss: 0.805982\n",
      "[6]\ttraining's multi_logloss: 0.771313\tvalid_1's multi_logloss: 0.799065\n",
      "[7]\ttraining's multi_logloss: 0.759702\tvalid_1's multi_logloss: 0.790606\n",
      "[8]\ttraining's multi_logloss: 0.749569\tvalid_1's multi_logloss: 0.784911\n",
      "[9]\ttraining's multi_logloss: 0.739357\tvalid_1's multi_logloss: 0.778101\n",
      "[10]\ttraining's multi_logloss: 0.730146\tvalid_1's multi_logloss: 0.771701\n",
      "[11]\ttraining's multi_logloss: 0.721278\tvalid_1's multi_logloss: 0.766636\n",
      "[12]\ttraining's multi_logloss: 0.712818\tvalid_1's multi_logloss: 0.762089\n",
      "[13]\ttraining's multi_logloss: 0.706193\tvalid_1's multi_logloss: 0.757684\n",
      "[14]\ttraining's multi_logloss: 0.698048\tvalid_1's multi_logloss: 0.75338\n",
      "[15]\ttraining's multi_logloss: 0.691888\tvalid_1's multi_logloss: 0.751148\n",
      "[16]\ttraining's multi_logloss: 0.685523\tvalid_1's multi_logloss: 0.749268\n",
      "[17]\ttraining's multi_logloss: 0.679871\tvalid_1's multi_logloss: 0.746269\n",
      "[18]\ttraining's multi_logloss: 0.674202\tvalid_1's multi_logloss: 0.742485\n",
      "[19]\ttraining's multi_logloss: 0.668327\tvalid_1's multi_logloss: 0.739622\n",
      "[20]\ttraining's multi_logloss: 0.663474\tvalid_1's multi_logloss: 0.73757\n",
      "[21]\ttraining's multi_logloss: 0.658248\tvalid_1's multi_logloss: 0.735142\n",
      "[22]\ttraining's multi_logloss: 0.653176\tvalid_1's multi_logloss: 0.732945\n",
      "[23]\ttraining's multi_logloss: 0.647745\tvalid_1's multi_logloss: 0.730447\n",
      "[24]\ttraining's multi_logloss: 0.64321\tvalid_1's multi_logloss: 0.728417\n",
      "[25]\ttraining's multi_logloss: 0.638865\tvalid_1's multi_logloss: 0.726853\n",
      "[26]\ttraining's multi_logloss: 0.633947\tvalid_1's multi_logloss: 0.724329\n",
      "[27]\ttraining's multi_logloss: 0.629765\tvalid_1's multi_logloss: 0.721237\n",
      "[28]\ttraining's multi_logloss: 0.62575\tvalid_1's multi_logloss: 0.720511\n",
      "[29]\ttraining's multi_logloss: 0.620823\tvalid_1's multi_logloss: 0.718906\n",
      "[30]\ttraining's multi_logloss: 0.616947\tvalid_1's multi_logloss: 0.717877\n",
      "[31]\ttraining's multi_logloss: 0.613247\tvalid_1's multi_logloss: 0.717067\n",
      "[32]\ttraining's multi_logloss: 0.609364\tvalid_1's multi_logloss: 0.713823\n",
      "[33]\ttraining's multi_logloss: 0.605219\tvalid_1's multi_logloss: 0.713358\n",
      "[34]\ttraining's multi_logloss: 0.601792\tvalid_1's multi_logloss: 0.712155\n",
      "[35]\ttraining's multi_logloss: 0.59852\tvalid_1's multi_logloss: 0.709818\n",
      "[36]\ttraining's multi_logloss: 0.594403\tvalid_1's multi_logloss: 0.709616\n",
      "[37]\ttraining's multi_logloss: 0.591133\tvalid_1's multi_logloss: 0.708073\n",
      "[38]\ttraining's multi_logloss: 0.587111\tvalid_1's multi_logloss: 0.707168\n",
      "[39]\ttraining's multi_logloss: 0.58334\tvalid_1's multi_logloss: 0.705797\n",
      "[40]\ttraining's multi_logloss: 0.578815\tvalid_1's multi_logloss: 0.704489\n",
      "[41]\ttraining's multi_logloss: 0.5754\tvalid_1's multi_logloss: 0.702596\n",
      "[42]\ttraining's multi_logloss: 0.572377\tvalid_1's multi_logloss: 0.701595\n",
      "[43]\ttraining's multi_logloss: 0.569207\tvalid_1's multi_logloss: 0.701892\n",
      "[44]\ttraining's multi_logloss: 0.566369\tvalid_1's multi_logloss: 0.700014\n",
      "[45]\ttraining's multi_logloss: 0.56339\tvalid_1's multi_logloss: 0.699413\n",
      "[46]\ttraining's multi_logloss: 0.56004\tvalid_1's multi_logloss: 0.699123\n",
      "[47]\ttraining's multi_logloss: 0.557251\tvalid_1's multi_logloss: 0.69872\n",
      "[48]\ttraining's multi_logloss: 0.554466\tvalid_1's multi_logloss: 0.696766\n",
      "[49]\ttraining's multi_logloss: 0.551419\tvalid_1's multi_logloss: 0.696636\n",
      "[50]\ttraining's multi_logloss: 0.548212\tvalid_1's multi_logloss: 0.69552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\ttraining's multi_logloss: 0.545168\tvalid_1's multi_logloss: 0.69382\n",
      "[52]\ttraining's multi_logloss: 0.541948\tvalid_1's multi_logloss: 0.692405\n",
      "[53]\ttraining's multi_logloss: 0.538977\tvalid_1's multi_logloss: 0.691502\n",
      "[54]\ttraining's multi_logloss: 0.535837\tvalid_1's multi_logloss: 0.690486\n",
      "[55]\ttraining's multi_logloss: 0.533095\tvalid_1's multi_logloss: 0.690057\n",
      "[56]\ttraining's multi_logloss: 0.530144\tvalid_1's multi_logloss: 0.689893\n",
      "[57]\ttraining's multi_logloss: 0.52757\tvalid_1's multi_logloss: 0.691355\n",
      "[58]\ttraining's multi_logloss: 0.524507\tvalid_1's multi_logloss: 0.689698\n",
      "[59]\ttraining's multi_logloss: 0.521574\tvalid_1's multi_logloss: 0.688706\n",
      "[60]\ttraining's multi_logloss: 0.519074\tvalid_1's multi_logloss: 0.687736\n",
      "[61]\ttraining's multi_logloss: 0.516113\tvalid_1's multi_logloss: 0.685123\n",
      "[62]\ttraining's multi_logloss: 0.513829\tvalid_1's multi_logloss: 0.6845\n",
      "[63]\ttraining's multi_logloss: 0.511441\tvalid_1's multi_logloss: 0.683976\n",
      "[64]\ttraining's multi_logloss: 0.508894\tvalid_1's multi_logloss: 0.683844\n",
      "[65]\ttraining's multi_logloss: 0.506293\tvalid_1's multi_logloss: 0.684006\n",
      "[66]\ttraining's multi_logloss: 0.503395\tvalid_1's multi_logloss: 0.683772\n",
      "[67]\ttraining's multi_logloss: 0.501079\tvalid_1's multi_logloss: 0.683208\n",
      "[68]\ttraining's multi_logloss: 0.498865\tvalid_1's multi_logloss: 0.683406\n",
      "[69]\ttraining's multi_logloss: 0.49624\tvalid_1's multi_logloss: 0.682609\n",
      "[70]\ttraining's multi_logloss: 0.49414\tvalid_1's multi_logloss: 0.68294\n",
      "[71]\ttraining's multi_logloss: 0.491243\tvalid_1's multi_logloss: 0.681911\n",
      "[72]\ttraining's multi_logloss: 0.488831\tvalid_1's multi_logloss: 0.682316\n",
      "[73]\ttraining's multi_logloss: 0.486246\tvalid_1's multi_logloss: 0.68138\n",
      "[74]\ttraining's multi_logloss: 0.483724\tvalid_1's multi_logloss: 0.681291\n",
      "[75]\ttraining's multi_logloss: 0.481454\tvalid_1's multi_logloss: 0.680914\n",
      "[76]\ttraining's multi_logloss: 0.479395\tvalid_1's multi_logloss: 0.680087\n",
      "[77]\ttraining's multi_logloss: 0.47733\tvalid_1's multi_logloss: 0.679848\n",
      "[78]\ttraining's multi_logloss: 0.475336\tvalid_1's multi_logloss: 0.679854\n",
      "[79]\ttraining's multi_logloss: 0.472853\tvalid_1's multi_logloss: 0.680573\n",
      "[80]\ttraining's multi_logloss: 0.470938\tvalid_1's multi_logloss: 0.680882\n",
      "[81]\ttraining's multi_logloss: 0.468792\tvalid_1's multi_logloss: 0.680868\n",
      "[82]\ttraining's multi_logloss: 0.466787\tvalid_1's multi_logloss: 0.681116\n",
      "[83]\ttraining's multi_logloss: 0.464726\tvalid_1's multi_logloss: 0.68014\n",
      "[84]\ttraining's multi_logloss: 0.462636\tvalid_1's multi_logloss: 0.679128\n",
      "[85]\ttraining's multi_logloss: 0.460594\tvalid_1's multi_logloss: 0.67911\n",
      "[86]\ttraining's multi_logloss: 0.458516\tvalid_1's multi_logloss: 0.679637\n",
      "[87]\ttraining's multi_logloss: 0.456342\tvalid_1's multi_logloss: 0.679099\n",
      "[88]\ttraining's multi_logloss: 0.454526\tvalid_1's multi_logloss: 0.68027\n",
      "[89]\ttraining's multi_logloss: 0.452197\tvalid_1's multi_logloss: 0.680302\n",
      "[90]\ttraining's multi_logloss: 0.450615\tvalid_1's multi_logloss: 0.679051\n",
      "[91]\ttraining's multi_logloss: 0.448812\tvalid_1's multi_logloss: 0.678825\n",
      "[92]\ttraining's multi_logloss: 0.447194\tvalid_1's multi_logloss: 0.679006\n",
      "[93]\ttraining's multi_logloss: 0.445123\tvalid_1's multi_logloss: 0.679352\n",
      "[94]\ttraining's multi_logloss: 0.443543\tvalid_1's multi_logloss: 0.678437\n",
      "[95]\ttraining's multi_logloss: 0.441593\tvalid_1's multi_logloss: 0.678193\n",
      "[96]\ttraining's multi_logloss: 0.439451\tvalid_1's multi_logloss: 0.678886\n",
      "[97]\ttraining's multi_logloss: 0.437486\tvalid_1's multi_logloss: 0.679101\n",
      "[98]\ttraining's multi_logloss: 0.435174\tvalid_1's multi_logloss: 0.679785\n",
      "[99]\ttraining's multi_logloss: 0.433182\tvalid_1's multi_logloss: 0.679154\n",
      "[100]\ttraining's multi_logloss: 0.431345\tvalid_1's multi_logloss: 0.678384\n",
      "[101]\ttraining's multi_logloss: 0.429583\tvalid_1's multi_logloss: 0.678634\n",
      "[102]\ttraining's multi_logloss: 0.427413\tvalid_1's multi_logloss: 0.677671\n",
      "[103]\ttraining's multi_logloss: 0.425286\tvalid_1's multi_logloss: 0.676877\n",
      "[104]\ttraining's multi_logloss: 0.423794\tvalid_1's multi_logloss: 0.677289\n",
      "[105]\ttraining's multi_logloss: 0.421848\tvalid_1's multi_logloss: 0.676597\n",
      "[106]\ttraining's multi_logloss: 0.420293\tvalid_1's multi_logloss: 0.677664\n",
      "[107]\ttraining's multi_logloss: 0.418762\tvalid_1's multi_logloss: 0.678711\n",
      "[108]\ttraining's multi_logloss: 0.416995\tvalid_1's multi_logloss: 0.677925\n",
      "[109]\ttraining's multi_logloss: 0.415259\tvalid_1's multi_logloss: 0.678207\n",
      "[110]\ttraining's multi_logloss: 0.413934\tvalid_1's multi_logloss: 0.678188\n",
      "[111]\ttraining's multi_logloss: 0.41225\tvalid_1's multi_logloss: 0.678464\n",
      "[112]\ttraining's multi_logloss: 0.410859\tvalid_1's multi_logloss: 0.678089\n",
      "[113]\ttraining's multi_logloss: 0.409319\tvalid_1's multi_logloss: 0.678065\n",
      "[114]\ttraining's multi_logloss: 0.407236\tvalid_1's multi_logloss: 0.677833\n",
      "[115]\ttraining's multi_logloss: 0.405481\tvalid_1's multi_logloss: 0.678086\n",
      "[116]\ttraining's multi_logloss: 0.403737\tvalid_1's multi_logloss: 0.679275\n",
      "[117]\ttraining's multi_logloss: 0.401812\tvalid_1's multi_logloss: 0.679497\n",
      "[118]\ttraining's multi_logloss: 0.400183\tvalid_1's multi_logloss: 0.679991\n",
      "[119]\ttraining's multi_logloss: 0.398832\tvalid_1's multi_logloss: 0.68\n",
      "[120]\ttraining's multi_logloss: 0.39745\tvalid_1's multi_logloss: 0.680103\n",
      "[121]\ttraining's multi_logloss: 0.395555\tvalid_1's multi_logloss: 0.679722\n",
      "[122]\ttraining's multi_logloss: 0.393998\tvalid_1's multi_logloss: 0.680001\n",
      "[123]\ttraining's multi_logloss: 0.392357\tvalid_1's multi_logloss: 0.680609\n",
      "[124]\ttraining's multi_logloss: 0.390901\tvalid_1's multi_logloss: 0.680836\n",
      "[125]\ttraining's multi_logloss: 0.389556\tvalid_1's multi_logloss: 0.680634\n",
      "[126]\ttraining's multi_logloss: 0.387739\tvalid_1's multi_logloss: 0.681407\n",
      "[127]\ttraining's multi_logloss: 0.386488\tvalid_1's multi_logloss: 0.681445\n",
      "[128]\ttraining's multi_logloss: 0.385007\tvalid_1's multi_logloss: 0.681437\n",
      "[129]\ttraining's multi_logloss: 0.383949\tvalid_1's multi_logloss: 0.681995\n",
      "[130]\ttraining's multi_logloss: 0.3827\tvalid_1's multi_logloss: 0.681626\n",
      "[131]\ttraining's multi_logloss: 0.381298\tvalid_1's multi_logloss: 0.682397\n",
      "[132]\ttraining's multi_logloss: 0.380001\tvalid_1's multi_logloss: 0.682319\n",
      "[133]\ttraining's multi_logloss: 0.378502\tvalid_1's multi_logloss: 0.682166\n",
      "[134]\ttraining's multi_logloss: 0.376913\tvalid_1's multi_logloss: 0.68309\n",
      "[135]\ttraining's multi_logloss: 0.37556\tvalid_1's multi_logloss: 0.683466\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's multi_logloss: 0.421848\tvalid_1's multi_logloss: 0.676597\n",
      "[1]\ttraining's multi_logloss: 0.856313\tvalid_1's multi_logloss: 0.861105\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.831083\tvalid_1's multi_logloss: 0.843831\n",
      "[3]\ttraining's multi_logloss: 0.811413\tvalid_1's multi_logloss: 0.829297\n",
      "[4]\ttraining's multi_logloss: 0.795038\tvalid_1's multi_logloss: 0.817687\n",
      "[5]\ttraining's multi_logloss: 0.779265\tvalid_1's multi_logloss: 0.806248\n",
      "[6]\ttraining's multi_logloss: 0.767611\tvalid_1's multi_logloss: 0.797678\n",
      "[7]\ttraining's multi_logloss: 0.755732\tvalid_1's multi_logloss: 0.789766\n",
      "[8]\ttraining's multi_logloss: 0.744836\tvalid_1's multi_logloss: 0.782312\n",
      "[9]\ttraining's multi_logloss: 0.735457\tvalid_1's multi_logloss: 0.77632\n",
      "[10]\ttraining's multi_logloss: 0.727509\tvalid_1's multi_logloss: 0.772622\n",
      "[11]\ttraining's multi_logloss: 0.719054\tvalid_1's multi_logloss: 0.765396\n",
      "[12]\ttraining's multi_logloss: 0.711077\tvalid_1's multi_logloss: 0.761977\n",
      "[13]\ttraining's multi_logloss: 0.703193\tvalid_1's multi_logloss: 0.757727\n",
      "[14]\ttraining's multi_logloss: 0.695876\tvalid_1's multi_logloss: 0.754218\n",
      "[15]\ttraining's multi_logloss: 0.68944\tvalid_1's multi_logloss: 0.750329\n",
      "[16]\ttraining's multi_logloss: 0.683599\tvalid_1's multi_logloss: 0.749378\n",
      "[17]\ttraining's multi_logloss: 0.677784\tvalid_1's multi_logloss: 0.747168\n",
      "[18]\ttraining's multi_logloss: 0.671364\tvalid_1's multi_logloss: 0.744856\n",
      "[19]\ttraining's multi_logloss: 0.665721\tvalid_1's multi_logloss: 0.744139\n",
      "[20]\ttraining's multi_logloss: 0.660146\tvalid_1's multi_logloss: 0.742798\n",
      "[21]\ttraining's multi_logloss: 0.654665\tvalid_1's multi_logloss: 0.740582\n",
      "[22]\ttraining's multi_logloss: 0.650197\tvalid_1's multi_logloss: 0.739329\n",
      "[23]\ttraining's multi_logloss: 0.644903\tvalid_1's multi_logloss: 0.737575\n",
      "[24]\ttraining's multi_logloss: 0.640841\tvalid_1's multi_logloss: 0.738224\n",
      "[25]\ttraining's multi_logloss: 0.636354\tvalid_1's multi_logloss: 0.737522\n",
      "[26]\ttraining's multi_logloss: 0.631946\tvalid_1's multi_logloss: 0.735884\n",
      "[27]\ttraining's multi_logloss: 0.627083\tvalid_1's multi_logloss: 0.73566\n",
      "[28]\ttraining's multi_logloss: 0.622492\tvalid_1's multi_logloss: 0.735033\n",
      "[29]\ttraining's multi_logloss: 0.617571\tvalid_1's multi_logloss: 0.733422\n",
      "[30]\ttraining's multi_logloss: 0.612444\tvalid_1's multi_logloss: 0.731671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttraining's multi_logloss: 0.608127\tvalid_1's multi_logloss: 0.731352\n",
      "[32]\ttraining's multi_logloss: 0.603562\tvalid_1's multi_logloss: 0.72999\n",
      "[33]\ttraining's multi_logloss: 0.599238\tvalid_1's multi_logloss: 0.73143\n",
      "[34]\ttraining's multi_logloss: 0.595907\tvalid_1's multi_logloss: 0.729863\n",
      "[35]\ttraining's multi_logloss: 0.592088\tvalid_1's multi_logloss: 0.729403\n",
      "[36]\ttraining's multi_logloss: 0.587769\tvalid_1's multi_logloss: 0.72786\n",
      "[37]\ttraining's multi_logloss: 0.584095\tvalid_1's multi_logloss: 0.728027\n",
      "[38]\ttraining's multi_logloss: 0.581093\tvalid_1's multi_logloss: 0.728043\n",
      "[39]\ttraining's multi_logloss: 0.577702\tvalid_1's multi_logloss: 0.726971\n",
      "[40]\ttraining's multi_logloss: 0.573524\tvalid_1's multi_logloss: 0.726093\n",
      "[41]\ttraining's multi_logloss: 0.570704\tvalid_1's multi_logloss: 0.725162\n",
      "[42]\ttraining's multi_logloss: 0.567327\tvalid_1's multi_logloss: 0.724579\n",
      "[43]\ttraining's multi_logloss: 0.56451\tvalid_1's multi_logloss: 0.724392\n",
      "[44]\ttraining's multi_logloss: 0.561144\tvalid_1's multi_logloss: 0.725458\n",
      "[45]\ttraining's multi_logloss: 0.558052\tvalid_1's multi_logloss: 0.72619\n",
      "[46]\ttraining's multi_logloss: 0.555063\tvalid_1's multi_logloss: 0.72643\n",
      "[47]\ttraining's multi_logloss: 0.551557\tvalid_1's multi_logloss: 0.726157\n",
      "[48]\ttraining's multi_logloss: 0.548079\tvalid_1's multi_logloss: 0.726101\n",
      "[49]\ttraining's multi_logloss: 0.545172\tvalid_1's multi_logloss: 0.725021\n",
      "[50]\ttraining's multi_logloss: 0.542529\tvalid_1's multi_logloss: 0.725654\n",
      "[51]\ttraining's multi_logloss: 0.539918\tvalid_1's multi_logloss: 0.725524\n",
      "[52]\ttraining's multi_logloss: 0.536708\tvalid_1's multi_logloss: 0.724126\n",
      "[53]\ttraining's multi_logloss: 0.533798\tvalid_1's multi_logloss: 0.723606\n",
      "[54]\ttraining's multi_logloss: 0.530447\tvalid_1's multi_logloss: 0.722761\n",
      "[55]\ttraining's multi_logloss: 0.527598\tvalid_1's multi_logloss: 0.722269\n",
      "[56]\ttraining's multi_logloss: 0.525259\tvalid_1's multi_logloss: 0.720992\n",
      "[57]\ttraining's multi_logloss: 0.522457\tvalid_1's multi_logloss: 0.721442\n",
      "[58]\ttraining's multi_logloss: 0.5198\tvalid_1's multi_logloss: 0.721566\n",
      "[59]\ttraining's multi_logloss: 0.516797\tvalid_1's multi_logloss: 0.721817\n",
      "[60]\ttraining's multi_logloss: 0.514276\tvalid_1's multi_logloss: 0.722832\n",
      "[61]\ttraining's multi_logloss: 0.511684\tvalid_1's multi_logloss: 0.723322\n",
      "[62]\ttraining's multi_logloss: 0.509452\tvalid_1's multi_logloss: 0.723271\n",
      "[63]\ttraining's multi_logloss: 0.506555\tvalid_1's multi_logloss: 0.722381\n",
      "[64]\ttraining's multi_logloss: 0.504434\tvalid_1's multi_logloss: 0.722165\n",
      "[65]\ttraining's multi_logloss: 0.50194\tvalid_1's multi_logloss: 0.722913\n",
      "[66]\ttraining's multi_logloss: 0.4991\tvalid_1's multi_logloss: 0.722431\n",
      "[67]\ttraining's multi_logloss: 0.496214\tvalid_1's multi_logloss: 0.722715\n",
      "[68]\ttraining's multi_logloss: 0.494015\tvalid_1's multi_logloss: 0.722713\n",
      "[69]\ttraining's multi_logloss: 0.491914\tvalid_1's multi_logloss: 0.723138\n",
      "[70]\ttraining's multi_logloss: 0.489926\tvalid_1's multi_logloss: 0.723167\n",
      "[71]\ttraining's multi_logloss: 0.487891\tvalid_1's multi_logloss: 0.72407\n",
      "[72]\ttraining's multi_logloss: 0.485296\tvalid_1's multi_logloss: 0.723303\n",
      "[73]\ttraining's multi_logloss: 0.482939\tvalid_1's multi_logloss: 0.724526\n",
      "[74]\ttraining's multi_logloss: 0.48079\tvalid_1's multi_logloss: 0.724546\n",
      "[75]\ttraining's multi_logloss: 0.47843\tvalid_1's multi_logloss: 0.723571\n",
      "[76]\ttraining's multi_logloss: 0.476484\tvalid_1's multi_logloss: 0.724009\n",
      "[77]\ttraining's multi_logloss: 0.473628\tvalid_1's multi_logloss: 0.724152\n",
      "[78]\ttraining's multi_logloss: 0.47082\tvalid_1's multi_logloss: 0.724094\n",
      "[79]\ttraining's multi_logloss: 0.46831\tvalid_1's multi_logloss: 0.724112\n",
      "[80]\ttraining's multi_logloss: 0.466072\tvalid_1's multi_logloss: 0.724602\n",
      "[81]\ttraining's multi_logloss: 0.464011\tvalid_1's multi_logloss: 0.725625\n",
      "[82]\ttraining's multi_logloss: 0.461891\tvalid_1's multi_logloss: 0.72463\n",
      "[83]\ttraining's multi_logloss: 0.460006\tvalid_1's multi_logloss: 0.724216\n",
      "[84]\ttraining's multi_logloss: 0.458254\tvalid_1's multi_logloss: 0.724824\n",
      "[85]\ttraining's multi_logloss: 0.456533\tvalid_1's multi_logloss: 0.725135\n",
      "[86]\ttraining's multi_logloss: 0.454371\tvalid_1's multi_logloss: 0.725973\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's multi_logloss: 0.525259\tvalid_1's multi_logloss: 0.720992\n",
      "[1]\ttraining's multi_logloss: 0.855356\tvalid_1's multi_logloss: 0.86575\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's multi_logloss: 0.830337\tvalid_1's multi_logloss: 0.848359\n",
      "[3]\ttraining's multi_logloss: 0.811858\tvalid_1's multi_logloss: 0.835722\n",
      "[4]\ttraining's multi_logloss: 0.794071\tvalid_1's multi_logloss: 0.82407\n",
      "[5]\ttraining's multi_logloss: 0.779721\tvalid_1's multi_logloss: 0.814971\n",
      "[6]\ttraining's multi_logloss: 0.767343\tvalid_1's multi_logloss: 0.808214\n",
      "[7]\ttraining's multi_logloss: 0.755199\tvalid_1's multi_logloss: 0.802951\n",
      "[8]\ttraining's multi_logloss: 0.743634\tvalid_1's multi_logloss: 0.7974\n",
      "[9]\ttraining's multi_logloss: 0.733502\tvalid_1's multi_logloss: 0.793212\n",
      "[10]\ttraining's multi_logloss: 0.724278\tvalid_1's multi_logloss: 0.78827\n",
      "[11]\ttraining's multi_logloss: 0.715856\tvalid_1's multi_logloss: 0.783371\n",
      "[12]\ttraining's multi_logloss: 0.707159\tvalid_1's multi_logloss: 0.780454\n",
      "[13]\ttraining's multi_logloss: 0.699741\tvalid_1's multi_logloss: 0.777883\n",
      "[14]\ttraining's multi_logloss: 0.693042\tvalid_1's multi_logloss: 0.774817\n",
      "[15]\ttraining's multi_logloss: 0.686782\tvalid_1's multi_logloss: 0.772118\n",
      "[16]\ttraining's multi_logloss: 0.680263\tvalid_1's multi_logloss: 0.770891\n",
      "[17]\ttraining's multi_logloss: 0.674357\tvalid_1's multi_logloss: 0.76748\n",
      "[18]\ttraining's multi_logloss: 0.669117\tvalid_1's multi_logloss: 0.765607\n",
      "[19]\ttraining's multi_logloss: 0.664207\tvalid_1's multi_logloss: 0.764296\n",
      "[20]\ttraining's multi_logloss: 0.658633\tvalid_1's multi_logloss: 0.762316\n",
      "[21]\ttraining's multi_logloss: 0.654211\tvalid_1's multi_logloss: 0.761607\n",
      "[22]\ttraining's multi_logloss: 0.64886\tvalid_1's multi_logloss: 0.75941\n",
      "[23]\ttraining's multi_logloss: 0.644506\tvalid_1's multi_logloss: 0.757745\n",
      "[24]\ttraining's multi_logloss: 0.640263\tvalid_1's multi_logloss: 0.757472\n",
      "[25]\ttraining's multi_logloss: 0.636556\tvalid_1's multi_logloss: 0.757007\n",
      "[26]\ttraining's multi_logloss: 0.632402\tvalid_1's multi_logloss: 0.755502\n",
      "[27]\ttraining's multi_logloss: 0.628042\tvalid_1's multi_logloss: 0.755147\n",
      "[28]\ttraining's multi_logloss: 0.624051\tvalid_1's multi_logloss: 0.754346\n",
      "[29]\ttraining's multi_logloss: 0.619686\tvalid_1's multi_logloss: 0.753744\n",
      "[30]\ttraining's multi_logloss: 0.615526\tvalid_1's multi_logloss: 0.75235\n",
      "[31]\ttraining's multi_logloss: 0.611208\tvalid_1's multi_logloss: 0.751718\n",
      "[32]\ttraining's multi_logloss: 0.607126\tvalid_1's multi_logloss: 0.749918\n",
      "[33]\ttraining's multi_logloss: 0.603592\tvalid_1's multi_logloss: 0.749626\n",
      "[34]\ttraining's multi_logloss: 0.600318\tvalid_1's multi_logloss: 0.75035\n",
      "[35]\ttraining's multi_logloss: 0.596038\tvalid_1's multi_logloss: 0.748814\n",
      "[36]\ttraining's multi_logloss: 0.591917\tvalid_1's multi_logloss: 0.749429\n",
      "[37]\ttraining's multi_logloss: 0.588574\tvalid_1's multi_logloss: 0.75038\n",
      "[38]\ttraining's multi_logloss: 0.585296\tvalid_1's multi_logloss: 0.750634\n",
      "[39]\ttraining's multi_logloss: 0.582134\tvalid_1's multi_logloss: 0.749574\n",
      "[40]\ttraining's multi_logloss: 0.578601\tvalid_1's multi_logloss: 0.751197\n",
      "[41]\ttraining's multi_logloss: 0.575254\tvalid_1's multi_logloss: 0.749273\n",
      "[42]\ttraining's multi_logloss: 0.571874\tvalid_1's multi_logloss: 0.74764\n",
      "[43]\ttraining's multi_logloss: 0.568634\tvalid_1's multi_logloss: 0.746312\n",
      "[44]\ttraining's multi_logloss: 0.565316\tvalid_1's multi_logloss: 0.745459\n",
      "[45]\ttraining's multi_logloss: 0.562075\tvalid_1's multi_logloss: 0.744522\n",
      "[46]\ttraining's multi_logloss: 0.558759\tvalid_1's multi_logloss: 0.742663\n",
      "[47]\ttraining's multi_logloss: 0.555351\tvalid_1's multi_logloss: 0.742039\n",
      "[48]\ttraining's multi_logloss: 0.552674\tvalid_1's multi_logloss: 0.741324\n",
      "[49]\ttraining's multi_logloss: 0.549813\tvalid_1's multi_logloss: 0.740735\n",
      "[50]\ttraining's multi_logloss: 0.546917\tvalid_1's multi_logloss: 0.7406\n",
      "[51]\ttraining's multi_logloss: 0.543881\tvalid_1's multi_logloss: 0.740833\n",
      "[52]\ttraining's multi_logloss: 0.540763\tvalid_1's multi_logloss: 0.740521\n",
      "[53]\ttraining's multi_logloss: 0.536948\tvalid_1's multi_logloss: 0.740265\n",
      "[54]\ttraining's multi_logloss: 0.534327\tvalid_1's multi_logloss: 0.740802\n",
      "[55]\ttraining's multi_logloss: 0.531626\tvalid_1's multi_logloss: 0.740799\n",
      "[56]\ttraining's multi_logloss: 0.528385\tvalid_1's multi_logloss: 0.740029\n",
      "[57]\ttraining's multi_logloss: 0.525617\tvalid_1's multi_logloss: 0.740352\n",
      "[58]\ttraining's multi_logloss: 0.523245\tvalid_1's multi_logloss: 0.73993\n",
      "[59]\ttraining's multi_logloss: 0.520415\tvalid_1's multi_logloss: 0.739995\n",
      "[60]\ttraining's multi_logloss: 0.517819\tvalid_1's multi_logloss: 0.738928\n",
      "[61]\ttraining's multi_logloss: 0.515652\tvalid_1's multi_logloss: 0.739329\n",
      "[62]\ttraining's multi_logloss: 0.512962\tvalid_1's multi_logloss: 0.73842\n",
      "[63]\ttraining's multi_logloss: 0.510078\tvalid_1's multi_logloss: 0.737408\n",
      "[64]\ttraining's multi_logloss: 0.507585\tvalid_1's multi_logloss: 0.737396\n",
      "[65]\ttraining's multi_logloss: 0.504965\tvalid_1's multi_logloss: 0.736679\n",
      "[66]\ttraining's multi_logloss: 0.502317\tvalid_1's multi_logloss: 0.736005\n",
      "[67]\ttraining's multi_logloss: 0.500011\tvalid_1's multi_logloss: 0.736009\n",
      "[68]\ttraining's multi_logloss: 0.498135\tvalid_1's multi_logloss: 0.735891\n",
      "[69]\ttraining's multi_logloss: 0.495653\tvalid_1's multi_logloss: 0.737046\n",
      "[70]\ttraining's multi_logloss: 0.493509\tvalid_1's multi_logloss: 0.735701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\ttraining's multi_logloss: 0.490804\tvalid_1's multi_logloss: 0.734931\n",
      "[72]\ttraining's multi_logloss: 0.488056\tvalid_1's multi_logloss: 0.734835\n",
      "[73]\ttraining's multi_logloss: 0.485327\tvalid_1's multi_logloss: 0.734598\n",
      "[74]\ttraining's multi_logloss: 0.482423\tvalid_1's multi_logloss: 0.734566\n",
      "[75]\ttraining's multi_logloss: 0.480258\tvalid_1's multi_logloss: 0.734643\n",
      "[76]\ttraining's multi_logloss: 0.477906\tvalid_1's multi_logloss: 0.734253\n",
      "[77]\ttraining's multi_logloss: 0.475269\tvalid_1's multi_logloss: 0.734081\n",
      "[78]\ttraining's multi_logloss: 0.472967\tvalid_1's multi_logloss: 0.733375\n",
      "[79]\ttraining's multi_logloss: 0.470861\tvalid_1's multi_logloss: 0.73406\n",
      "[80]\ttraining's multi_logloss: 0.468765\tvalid_1's multi_logloss: 0.735068\n",
      "[81]\ttraining's multi_logloss: 0.466536\tvalid_1's multi_logloss: 0.734389\n",
      "[82]\ttraining's multi_logloss: 0.464284\tvalid_1's multi_logloss: 0.733651\n",
      "[83]\ttraining's multi_logloss: 0.46254\tvalid_1's multi_logloss: 0.734316\n",
      "[84]\ttraining's multi_logloss: 0.460546\tvalid_1's multi_logloss: 0.734581\n",
      "[85]\ttraining's multi_logloss: 0.45826\tvalid_1's multi_logloss: 0.733994\n",
      "[86]\ttraining's multi_logloss: 0.456222\tvalid_1's multi_logloss: 0.73488\n",
      "[87]\ttraining's multi_logloss: 0.453934\tvalid_1's multi_logloss: 0.734956\n",
      "[88]\ttraining's multi_logloss: 0.451853\tvalid_1's multi_logloss: 0.734437\n",
      "[89]\ttraining's multi_logloss: 0.44976\tvalid_1's multi_logloss: 0.733383\n",
      "[90]\ttraining's multi_logloss: 0.448056\tvalid_1's multi_logloss: 0.733607\n",
      "[91]\ttraining's multi_logloss: 0.446001\tvalid_1's multi_logloss: 0.732895\n",
      "[92]\ttraining's multi_logloss: 0.443693\tvalid_1's multi_logloss: 0.732417\n",
      "[93]\ttraining's multi_logloss: 0.441848\tvalid_1's multi_logloss: 0.733447\n",
      "[94]\ttraining's multi_logloss: 0.440091\tvalid_1's multi_logloss: 0.733178\n",
      "[95]\ttraining's multi_logloss: 0.438079\tvalid_1's multi_logloss: 0.73272\n",
      "[96]\ttraining's multi_logloss: 0.435923\tvalid_1's multi_logloss: 0.732062\n",
      "[97]\ttraining's multi_logloss: 0.434447\tvalid_1's multi_logloss: 0.732317\n",
      "[98]\ttraining's multi_logloss: 0.432902\tvalid_1's multi_logloss: 0.733129\n",
      "[99]\ttraining's multi_logloss: 0.431069\tvalid_1's multi_logloss: 0.733117\n",
      "[100]\ttraining's multi_logloss: 0.429218\tvalid_1's multi_logloss: 0.732354\n",
      "[101]\ttraining's multi_logloss: 0.427333\tvalid_1's multi_logloss: 0.732796\n",
      "[102]\ttraining's multi_logloss: 0.425243\tvalid_1's multi_logloss: 0.733423\n",
      "[103]\ttraining's multi_logloss: 0.423804\tvalid_1's multi_logloss: 0.734441\n",
      "[104]\ttraining's multi_logloss: 0.422116\tvalid_1's multi_logloss: 0.734078\n",
      "[105]\ttraining's multi_logloss: 0.420197\tvalid_1's multi_logloss: 0.734599\n",
      "[106]\ttraining's multi_logloss: 0.41841\tvalid_1's multi_logloss: 0.735508\n",
      "[107]\ttraining's multi_logloss: 0.41698\tvalid_1's multi_logloss: 0.735614\n",
      "[108]\ttraining's multi_logloss: 0.41521\tvalid_1's multi_logloss: 0.734835\n",
      "[109]\ttraining's multi_logloss: 0.41353\tvalid_1's multi_logloss: 0.734544\n",
      "[110]\ttraining's multi_logloss: 0.411828\tvalid_1's multi_logloss: 0.735192\n",
      "[111]\ttraining's multi_logloss: 0.409712\tvalid_1's multi_logloss: 0.735249\n",
      "[112]\ttraining's multi_logloss: 0.408085\tvalid_1's multi_logloss: 0.735198\n",
      "[113]\ttraining's multi_logloss: 0.406512\tvalid_1's multi_logloss: 0.734807\n",
      "[114]\ttraining's multi_logloss: 0.405123\tvalid_1's multi_logloss: 0.734638\n",
      "[115]\ttraining's multi_logloss: 0.403392\tvalid_1's multi_logloss: 0.733847\n",
      "[116]\ttraining's multi_logloss: 0.401809\tvalid_1's multi_logloss: 0.732784\n",
      "[117]\ttraining's multi_logloss: 0.400244\tvalid_1's multi_logloss: 0.732717\n",
      "[118]\ttraining's multi_logloss: 0.398539\tvalid_1's multi_logloss: 0.733029\n",
      "[119]\ttraining's multi_logloss: 0.397187\tvalid_1's multi_logloss: 0.733732\n",
      "[120]\ttraining's multi_logloss: 0.39601\tvalid_1's multi_logloss: 0.733933\n",
      "[121]\ttraining's multi_logloss: 0.394188\tvalid_1's multi_logloss: 0.733251\n",
      "[122]\ttraining's multi_logloss: 0.392586\tvalid_1's multi_logloss: 0.734323\n",
      "[123]\ttraining's multi_logloss: 0.390687\tvalid_1's multi_logloss: 0.734682\n",
      "[124]\ttraining's multi_logloss: 0.389153\tvalid_1's multi_logloss: 0.735114\n",
      "[125]\ttraining's multi_logloss: 0.387501\tvalid_1's multi_logloss: 0.735484\n",
      "[126]\ttraining's multi_logloss: 0.385776\tvalid_1's multi_logloss: 0.735027\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's multi_logloss: 0.435923\tvalid_1's multi_logloss: 0.732062\n",
      "평균{ls}\n"
     ]
    }
   ],
   "source": [
    "out_loss, out_models = tr(out_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "biblical-ballot",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.62038\tvalid_1's multi_logloss: 0.744209\n",
      "[200]\ttraining's multi_logloss: 0.521963\tvalid_1's multi_logloss: 0.729235\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttraining's multi_logloss: 0.47498\tvalid_1's multi_logloss: 0.725871\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.625355\tvalid_1's multi_logloss: 0.737295\n",
      "[200]\ttraining's multi_logloss: 0.526116\tvalid_1's multi_logloss: 0.72286\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's multi_logloss: 0.511477\tvalid_1's multi_logloss: 0.721449\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.615785\tvalid_1's multi_logloss: 0.755351\n",
      "[200]\ttraining's multi_logloss: 0.517087\tvalid_1's multi_logloss: 0.743465\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's multi_logloss: 0.471513\tvalid_1's multi_logloss: 0.741379\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.622613\tvalid_1's multi_logloss: 0.747395\n",
      "[200]\ttraining's multi_logloss: 0.524092\tvalid_1's multi_logloss: 0.736255\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's multi_logloss: 0.501196\tvalid_1's multi_logloss: 0.735222\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.618187\tvalid_1's multi_logloss: 0.749456\n",
      "[200]\ttraining's multi_logloss: 0.519773\tvalid_1's multi_logloss: 0.73922\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's multi_logloss: 0.504483\tvalid_1's multi_logloss: 0.738651\n",
      "================================================================================\n",
      "\n",
      "\n",
      "0.7325143920950408\n"
     ]
    }
   ],
   "source": [
    "in_loss, in_models = tr(in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "numerous-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_zeros = np.zeros([len(in_test),3])\n",
    "for fold in range(5):\n",
    "    in_zeros += in_models[fold].predict_proba(in_test)/5\n",
    "in_output = pd.DataFrame(in_zeros)\n",
    "in_output = in_output.reindex(index=pd.Index(idx_in_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "sacred-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "in2 = np.concatenate((in_zeros,np.array(idx_in_test).reshape(-1,1)),axis=1)\n",
    "out2 = np.concatenate((out_zeros,np.array(idx_out_test).reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "false-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(np.concatenate((in2,out2),axis=0),columns=[0,1,2,'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "intensive-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['index'] = output['index'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "middle-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(d + '\\\\' +lst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "imposed-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254328</td>\n",
       "      <td>0.176459</td>\n",
       "      <td>0.569213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037702</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.885179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150319</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.744263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.168475</td>\n",
       "      <td>0.757084</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057947</td>\n",
       "      <td>0.112467</td>\n",
       "      <td>0.829586</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.045256</td>\n",
       "      <td>0.062820</td>\n",
       "      <td>0.891924</td>\n",
       "      <td>9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.113289</td>\n",
       "      <td>0.091170</td>\n",
       "      <td>0.795541</td>\n",
       "      <td>9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.162660</td>\n",
       "      <td>0.185026</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.231756</td>\n",
       "      <td>0.133885</td>\n",
       "      <td>0.634359</td>\n",
       "      <td>9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>9994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2  index\n",
       "0     0.254328  0.176459  0.569213      1\n",
       "1     0.037702  0.077119  0.885179      2\n",
       "2     0.150319  0.105418  0.744263      3\n",
       "3     0.074441  0.168475  0.757084      4\n",
       "4     0.057947  0.112467  0.829586      5\n",
       "...        ...       ...       ...    ...\n",
       "9995  0.045256  0.062820  0.891924   9968\n",
       "9996  0.113289  0.091170  0.795541   9981\n",
       "9997  0.162660  0.185026  0.652315   9988\n",
       "9998  0.231756  0.133885  0.634359   9992\n",
       "9999  0.083838  0.910228  0.005934   9994\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "incoming-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output)):\n",
    "    row = output.loc[output['index']==i]\n",
    "    ss.iloc[i,1:] = row.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "extraordinary-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('two_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "primary-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254328</td>\n",
       "      <td>0.176459</td>\n",
       "      <td>0.569213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037702</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.885179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150319</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.744263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.168475</td>\n",
       "      <td>0.757084</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057947</td>\n",
       "      <td>0.112467</td>\n",
       "      <td>0.829586</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  index\n",
       "0  0.254328  0.176459  0.569213      1\n",
       "1  0.037702  0.077119  0.885179      2\n",
       "2  0.150319  0.105418  0.744263      3\n",
       "3  0.074441  0.168475  0.757084      4\n",
       "4  0.057947  0.112467  0.829586      5"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "perceived-seattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.045256</td>\n",
       "      <td>0.062820</td>\n",
       "      <td>0.891924</td>\n",
       "      <td>9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.113289</td>\n",
       "      <td>0.091170</td>\n",
       "      <td>0.795541</td>\n",
       "      <td>9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.162660</td>\n",
       "      <td>0.185026</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.231756</td>\n",
       "      <td>0.133885</td>\n",
       "      <td>0.634359</td>\n",
       "      <td>9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>9994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2  index\n",
       "9995  0.045256  0.062820  0.891924   9968\n",
       "9996  0.113289  0.091170  0.795541   9981\n",
       "9997  0.162660  0.185026  0.652315   9988\n",
       "9998  0.231756  0.133885  0.634359   9992\n",
       "9999  0.083838  0.910228  0.005934   9994"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
