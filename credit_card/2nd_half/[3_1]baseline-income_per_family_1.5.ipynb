{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "devoted-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'sample_submission.csv', 'test.csv', 'train.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "d = \"C:\\kaggle_data\\credit_card\"\n",
    "lst = os.listdir(d)\n",
    "print(lst)\n",
    "train = pd.read_csv(d + '\\\\' +lst[3])\n",
    "test = pd.read_csv(d + '\\\\' +lst[2])\n",
    "ss = pd.read_csv(d + '\\\\' +lst[1])\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True) \n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-guatemala",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efficient-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['income_per_size'] = np.log(train['income_total']/train['family_size'])\n",
    "test['income_per_size'] = np.log(test['income_total']/test['family_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-attention",
   "metadata": {},
   "source": [
    "### family_type\n",
    "- Civil marriage: 종교의식 없이 그냥 결혼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "necessary-bride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Married', 'Civil marriage', 'Separated', 'Single / not married',\n",
       "       'Widow'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['family_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "internal-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Married, Civil marriage\n",
    "train.loc[(train['family_type']=='Married')|(train['family_type']=='Civil marriage'),'income_per_size']\\\n",
    "= train['income_per_size'] * 2.2\n",
    "\n",
    "test.loc[(test['family_type']=='Married')|(test['family_type']=='Civil marriage'),'income_per_size']\\\n",
    "= test['income_per_size'] * 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increasing-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_total을 로그변환 한 새로운 feature log_income\n",
    "# 기존 칼럼 삭제\n",
    "train['log_income'] = np.log(train['income_total'])\n",
    "train = train.drop('income_total',1)\n",
    "test['log_income'] = np.log(test['income_total'])\n",
    "test = test.drop('income_total',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "constant-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car와 reality를 합친 새로운 칼럼 careality\n",
    "train['careality'] = train['car'] + train['reality']\n",
    "train = train.drop(['car', 'reality'],1)\n",
    "\n",
    "test['careality'] = test['car'] + test['reality']\n",
    "test = test.drop(['car', 'reality'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latest-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "maritime-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "informal-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-dating",
   "metadata": {},
   "source": [
    "# 모델링, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spoken-sending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.646009\tvalid_1's multi_logloss: 0.749493\n",
      "[200]\ttraining's multi_logloss: 0.55779\tvalid_1's multi_logloss: 0.731471\n",
      "[300]\ttraining's multi_logloss: 0.495709\tvalid_1's multi_logloss: 0.723063\n",
      "[400]\ttraining's multi_logloss: 0.4432\tvalid_1's multi_logloss: 0.721638\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's multi_logloss: 0.441529\tvalid_1's multi_logloss: 0.721517\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.642517\tvalid_1's multi_logloss: 0.760614\n",
      "[200]\ttraining's multi_logloss: 0.556102\tvalid_1's multi_logloss: 0.74657\n",
      "[300]\ttraining's multi_logloss: 0.491893\tvalid_1's multi_logloss: 0.743572\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's multi_logloss: 0.486562\tvalid_1's multi_logloss: 0.743009\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.648089\tvalid_1's multi_logloss: 0.756029\n",
      "[200]\ttraining's multi_logloss: 0.556803\tvalid_1's multi_logloss: 0.740899\n",
      "[300]\ttraining's multi_logloss: 0.489851\tvalid_1's multi_logloss: 0.736232\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttraining's multi_logloss: 0.48413\tvalid_1's multi_logloss: 0.735725\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.642604\tvalid_1's multi_logloss: 0.748122\n",
      "[200]\ttraining's multi_logloss: 0.555875\tvalid_1's multi_logloss: 0.732213\n",
      "[300]\ttraining's multi_logloss: 0.491849\tvalid_1's multi_logloss: 0.727732\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's multi_logloss: 0.496055\tvalid_1's multi_logloss: 0.727294\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.646791\tvalid_1's multi_logloss: 0.750622\n",
      "[200]\ttraining's multi_logloss: 0.556786\tvalid_1's multi_logloss: 0.736364\n",
      "[300]\ttraining's multi_logloss: 0.492293\tvalid_1's multi_logloss: 0.732569\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's multi_logloss: 0.499061\tvalid_1's multi_logloss: 0.732478\n",
      "================================================================================\n",
      "\n",
      "\n",
      "0.7320045364692163\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "losses=[]\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))\n",
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(n_estimators=1000)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    losses.append(log_loss(y_valid, lgb.predict_proba(X_valid)))\n",
    "    print(f'================================================================================\\n\\n')\n",
    "print(sum(losses)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *2   : 0.7320045364692163\n",
    "# *1.5 : 0.73256224349757\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "twelve-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.iloc[:,1:]=0\n",
    "for fold in range(5):\n",
    "    ss.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sustainable-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('baseline_ips_marriage.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
