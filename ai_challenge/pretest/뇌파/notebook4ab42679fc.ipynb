{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/defense-project/train_data.csv\n/kaggle/input/defense-project/test_data.csv\n/kaggle/input/defense-project/submissions_sample.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras import models\nfrom keras import layers","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/defense-project/train_data.csv')\ntest = pd.read_csv('/kaggle/input/defense-project/test_data.csv')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny_train = train.pop('label')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   # mean_0_a  mean_1_a  mean_2_a   mean_3_a  mean_4_a  mean_d_0_a  \\\n0   26.700000     31.00      34.5  24.217760      26.7   -3.470000   \n1   28.800000     32.70      35.0  26.393804      24.4    1.870000   \n2   15.667977     25.90    -141.0  15.258776      26.2   -7.354916   \n3   30.900000     32.00      31.8  29.000000      25.6   -4.571665   \n4   -3.190000      4.83      14.4 -14.700000      17.7  105.989487   \n\n   mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...   fft_740_b  fft_741_b  \\\n0       -0.17   -2.555242       -1.44     6.31587  ...  199.000000      -29.3   \n1        1.65    8.770000        1.24     2.58000  ...  101.000000       25.9   \n2       -2.35    3.715261       -6.29     7.60000  ...   47.100000       80.8   \n3       -1.43   -1.220000       -2.39     1.49000  ...  106.943135      -19.1   \n4       -4.32  -11.900000      111.00    -2.91000  ...   71.400000       41.5   \n\n   fft_742_b  fft_743_b  fft_744_b   fft_745_b  fft_746_b   fft_747_b  \\\n0       26.8       26.8 -29.300000  193.000000      -4.11  -17.174885   \n1       -2.9       -2.9  25.905983   69.441984      -7.10   39.200000   \n2      -33.1      -33.1  80.800000  346.000000    -219.00  108.230070   \n3       26.6       26.6 -19.100000  215.000000      14.40  -43.500000   \n4       21.3       21.3  41.500000   52.154572      18.80  -53.612488   \n\n   fft_748_b  fft_749_b  \n0      -17.1      -4.11  \n1       39.2      -7.10  \n2      109.0    -219.00  \n3      -43.5      14.40  \n4      -53.6      18.80  \n\n[5 rows x 2548 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># mean_0_a</th>\n      <th>mean_1_a</th>\n      <th>mean_2_a</th>\n      <th>mean_3_a</th>\n      <th>mean_4_a</th>\n      <th>mean_d_0_a</th>\n      <th>mean_d_1_a</th>\n      <th>mean_d_2_a</th>\n      <th>mean_d_3_a</th>\n      <th>mean_d_4_a</th>\n      <th>...</th>\n      <th>fft_740_b</th>\n      <th>fft_741_b</th>\n      <th>fft_742_b</th>\n      <th>fft_743_b</th>\n      <th>fft_744_b</th>\n      <th>fft_745_b</th>\n      <th>fft_746_b</th>\n      <th>fft_747_b</th>\n      <th>fft_748_b</th>\n      <th>fft_749_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26.700000</td>\n      <td>31.00</td>\n      <td>34.5</td>\n      <td>24.217760</td>\n      <td>26.7</td>\n      <td>-3.470000</td>\n      <td>-0.17</td>\n      <td>-2.555242</td>\n      <td>-1.44</td>\n      <td>6.31587</td>\n      <td>...</td>\n      <td>199.000000</td>\n      <td>-29.3</td>\n      <td>26.8</td>\n      <td>26.8</td>\n      <td>-29.300000</td>\n      <td>193.000000</td>\n      <td>-4.11</td>\n      <td>-17.174885</td>\n      <td>-17.1</td>\n      <td>-4.11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28.800000</td>\n      <td>32.70</td>\n      <td>35.0</td>\n      <td>26.393804</td>\n      <td>24.4</td>\n      <td>1.870000</td>\n      <td>1.65</td>\n      <td>8.770000</td>\n      <td>1.24</td>\n      <td>2.58000</td>\n      <td>...</td>\n      <td>101.000000</td>\n      <td>25.9</td>\n      <td>-2.9</td>\n      <td>-2.9</td>\n      <td>25.905983</td>\n      <td>69.441984</td>\n      <td>-7.10</td>\n      <td>39.200000</td>\n      <td>39.2</td>\n      <td>-7.10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15.667977</td>\n      <td>25.90</td>\n      <td>-141.0</td>\n      <td>15.258776</td>\n      <td>26.2</td>\n      <td>-7.354916</td>\n      <td>-2.35</td>\n      <td>3.715261</td>\n      <td>-6.29</td>\n      <td>7.60000</td>\n      <td>...</td>\n      <td>47.100000</td>\n      <td>80.8</td>\n      <td>-33.1</td>\n      <td>-33.1</td>\n      <td>80.800000</td>\n      <td>346.000000</td>\n      <td>-219.00</td>\n      <td>108.230070</td>\n      <td>109.0</td>\n      <td>-219.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30.900000</td>\n      <td>32.00</td>\n      <td>31.8</td>\n      <td>29.000000</td>\n      <td>25.6</td>\n      <td>-4.571665</td>\n      <td>-1.43</td>\n      <td>-1.220000</td>\n      <td>-2.39</td>\n      <td>1.49000</td>\n      <td>...</td>\n      <td>106.943135</td>\n      <td>-19.1</td>\n      <td>26.6</td>\n      <td>26.6</td>\n      <td>-19.100000</td>\n      <td>215.000000</td>\n      <td>14.40</td>\n      <td>-43.500000</td>\n      <td>-43.5</td>\n      <td>14.40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-3.190000</td>\n      <td>4.83</td>\n      <td>14.4</td>\n      <td>-14.700000</td>\n      <td>17.7</td>\n      <td>105.989487</td>\n      <td>-4.32</td>\n      <td>-11.900000</td>\n      <td>111.00</td>\n      <td>-2.91000</td>\n      <td>...</td>\n      <td>71.400000</td>\n      <td>41.5</td>\n      <td>21.3</td>\n      <td>21.3</td>\n      <td>41.500000</td>\n      <td>52.154572</td>\n      <td>18.80</td>\n      <td>-53.612488</td>\n      <td>-53.6</td>\n      <td>18.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2548 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = train.mean(axis=0)\ntrain -= mean\nstd = train.std(axis=0)\ntrain /= std\n\ntest-= mean\ntest /= std","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train, y_train)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n0      -0.028437 -0.027735 -0.023761  0.034163 -0.019281    0.027980   \n1      -0.028437 -0.027735 -0.023745  0.034169 -0.019281    0.028058   \n2      -0.028437 -0.027735 -0.029121  0.034141 -0.019281    0.027923   \n3      -0.028437 -0.027735 -0.023843  0.034175 -0.019281    0.027964   \n4      -0.028437 -0.027735 -0.024375  0.034065 -0.019281    0.029576   \n...          ...       ...       ...       ...       ...         ...   \n1295   -0.028437 -0.027735 -0.024243  0.034113 -0.019281    0.028085   \n1296   -0.028437 -0.027735 -0.023971  0.034172 -0.019281    0.028039   \n1297   -0.028437 -0.027735 -0.024368  0.034062 -0.019281    0.028009   \n1298   -0.028437 -0.027735 -0.024433  0.034043 -0.019281    0.027978   \n1299   -0.028437 -0.027735 -0.029243  0.034133 -0.019281    0.028076   \n\n      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_740_b  \\\n0      -0.024939    0.024224    0.025683   -0.027738  ...  -0.026900   \n1      -0.024939    0.024224    0.025683   -0.027738  ...  -0.027300   \n2      -0.024939    0.024224    0.025683   -0.027738  ...  -0.027520   \n3      -0.024939    0.024224    0.025683   -0.027738  ...  -0.027276   \n4      -0.024939    0.024224    0.025683   -0.027738  ...  -0.027421   \n...          ...         ...         ...         ...  ...        ...   \n1295   -0.024939    0.024224    0.025683   -0.027738  ...  -0.027374   \n1296   -0.024939    0.024224    0.025683   -0.027738  ...  -0.027263   \n1297   -0.024939    0.024224    0.025683   -0.027738  ...  -0.027764   \n1298   -0.024939    0.024224    0.025683   -0.027738  ...  -0.027792   \n1299   -0.024939    0.024224    0.025683   -0.027738  ...  -0.026544   \n\n      fft_741_b  fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  \\\n0      0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028908   \n1      0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028945   \n2      0.025134   0.027757   -0.03729   0.027714  -0.027753  -0.031562   \n3      0.025134   0.027757   -0.03729   0.027714  -0.027753  -0.028680   \n4      0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028625   \n...         ...        ...        ...        ...        ...        ...   \n1295   0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028874   \n1296   0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028815   \n1297   0.025134   0.027757   -0.03729   0.027714  -0.027754  -0.028762   \n1298   0.025134   0.027757   -0.03729   0.027714  -0.027755  -0.029017   \n1299   0.025134   0.027757   -0.03729   0.027714  -0.027757  -0.024078   \n\n      fft_747_b  fft_748_b  fft_749_b  \n0      0.030695  -0.027446  -0.383296  \n1      0.030695  -0.027446  -0.395391  \n2      0.030695  -0.027446  -1.252548  \n3      0.030695  -0.027446  -0.308421  \n4      0.030695  -0.027446  -0.290623  \n...         ...        ...        ...  \n1295   0.030695  -0.027446  -0.371942  \n1296   0.030695  -0.027446  -0.352796  \n1297   0.030695  -0.027446  -0.335321  \n1298   0.030695  -0.027446  -0.418853  \n1299   0.030695  -0.027446   1.198900  \n\n[1300 rows x 2548 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># mean_0_a</th>\n      <th>mean_1_a</th>\n      <th>mean_2_a</th>\n      <th>mean_3_a</th>\n      <th>mean_4_a</th>\n      <th>mean_d_0_a</th>\n      <th>mean_d_1_a</th>\n      <th>mean_d_2_a</th>\n      <th>mean_d_3_a</th>\n      <th>mean_d_4_a</th>\n      <th>...</th>\n      <th>fft_740_b</th>\n      <th>fft_741_b</th>\n      <th>fft_742_b</th>\n      <th>fft_743_b</th>\n      <th>fft_744_b</th>\n      <th>fft_745_b</th>\n      <th>fft_746_b</th>\n      <th>fft_747_b</th>\n      <th>fft_748_b</th>\n      <th>fft_749_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.023761</td>\n      <td>0.034163</td>\n      <td>-0.019281</td>\n      <td>0.027980</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.026900</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028908</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.383296</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.023745</td>\n      <td>0.034169</td>\n      <td>-0.019281</td>\n      <td>0.028058</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027300</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028945</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.395391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.029121</td>\n      <td>0.034141</td>\n      <td>-0.019281</td>\n      <td>0.027923</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027520</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027753</td>\n      <td>-0.031562</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-1.252548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.023843</td>\n      <td>0.034175</td>\n      <td>-0.019281</td>\n      <td>0.027964</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027276</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027753</td>\n      <td>-0.028680</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.308421</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.024375</td>\n      <td>0.034065</td>\n      <td>-0.019281</td>\n      <td>0.029576</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027421</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028625</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.290623</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.024243</td>\n      <td>0.034113</td>\n      <td>-0.019281</td>\n      <td>0.028085</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027374</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028874</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.371942</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.023971</td>\n      <td>0.034172</td>\n      <td>-0.019281</td>\n      <td>0.028039</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027263</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028815</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.352796</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.024368</td>\n      <td>0.034062</td>\n      <td>-0.019281</td>\n      <td>0.028009</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027764</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027754</td>\n      <td>-0.028762</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.335321</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.024433</td>\n      <td>0.034043</td>\n      <td>-0.019281</td>\n      <td>0.027978</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.027792</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027755</td>\n      <td>-0.029017</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>-0.418853</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>-0.028437</td>\n      <td>-0.027735</td>\n      <td>-0.029243</td>\n      <td>0.034133</td>\n      <td>-0.019281</td>\n      <td>0.028076</td>\n      <td>-0.024939</td>\n      <td>0.024224</td>\n      <td>0.025683</td>\n      <td>-0.027738</td>\n      <td>...</td>\n      <td>-0.026544</td>\n      <td>0.025134</td>\n      <td>0.027757</td>\n      <td>-0.03729</td>\n      <td>0.027714</td>\n      <td>-0.027757</td>\n      <td>-0.024078</td>\n      <td>0.030695</td>\n      <td>-0.027446</td>\n      <td>1.198900</td>\n    </tr>\n  </tbody>\n</table>\n<p>1300 rows × 2548 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(32,activation = 'tanh' ,input_shape=(2548,)))\nmodel.add(layers.Dense(32,activation = 'tanh'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(32,activation = 'tanh'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(32,activation = 'tanh'))\nmodel.add(layers.Dense(3,activation='softmax'))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":23,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_9 (Dense)              (None, 32)                81568     \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_13 (Dense)             (None, 3)                 99        \n=================================================================\nTotal params: 84,835\nTrainable params: 84,835\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'rmsprop',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"1223    0\n385     1\n882     2\n329     2\n545     0\n       ..\n797     2\n338     1\n830     2\n1244    0\n937     2\nName: label, Length: 325, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val = to_categorical(y_val)\ny_train = to_categorical(y_train)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"array([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs = 20, batch_size=64,validation_data=(X_val,y_val))","execution_count":30,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"Creating variables on a non-first call to a function decorated with tf.function.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-3afe0913ebf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    814\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    817\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\nxgb_clf = XGBClassifier(n_estimators=100, random_state=1123, learning_rate=0.02,max_depth=5)\nxgb_clf.fit(X_train,y_train,eval_metric='error',eval_set=[(X_train,y_train),(X_test,y_test)])\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}